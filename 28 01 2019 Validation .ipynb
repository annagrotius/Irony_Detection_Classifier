{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import/install all packages at the top\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "\n",
    "from features_stats import *\n",
    "from classification_stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections:\n",
    "\n",
    "# (1) Import dataset and split\n",
    "\n",
    "# (2) Functions\n",
    "\n",
    "# (3) Validation Testing (obtain stats ready for comparison)\n",
    "------- get stats and create summary df\n",
    "- (3.1) Average Word Count\n",
    "- (3.2) Average Sentence Count\n",
    "- (3.3) Punctuation Richness\n",
    "- (3.4) Sarcasm Symbol\n",
    "- (3.5) Upper-case Words\n",
    "- (3.6) (Verb) Lemmas\n",
    "- (3.7) Sentiment Classification\n",
    "\n",
    "- (3.8) Individual Punctuation Count\n",
    "- (3.9) Word Type Count\n",
    "- (3.10) Named Entity Count\n",
    "\n",
    "# (4) Additional Functions for Classification\n",
    "# (5) Classification\n",
    "# (5) Classification Results\n",
    "# (6) Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Import and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Read file as DF with PANDAS (for better visualisation)\n",
    "filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/irony-labeled.csv\"\n",
    "gold_label = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the columns\n",
    "gold_label.columns = [\"Comment_Text\", \"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to get two DFs (prep for split)\n",
    "\n",
    "y = gold_label[\"Comment_Text\"]\n",
    "x = gold_label[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into TEST and TRAIN sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=43)\n",
    "\n",
    "#Split the TRAIN set again to get VALIDATION set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOIN the series together to get final splits as DFs\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "val = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data contains 47 IRONIC comments\n",
      "Validation data contains 148 NON- IRONIC comments\n"
     ]
    }
   ],
   "source": [
    "#Check number of comments labelled as ironic vs non-ironic\n",
    "ironic_val = val[val[\"Label\"] == 1]\n",
    "nonironic_val = val[val[\"Label\"] == -1]\n",
    "\n",
    "print(f\"Validation data contains {len(ironic_val)} IRONIC comments\")\n",
    "print(f\"Validation data contains {len(nonironic_val)} NON- IRONIC comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "#Convert TEST(validation) set into a dictionary\n",
    "val_dict = val.set_index(val.index).T.to_dict()\n",
    "\n",
    "print(len(val_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Validation Tetsing\n",
    "- Obtain all statistics (based on training) ready for comparison in next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) GET ALL TOKENS\n",
    "tokens = get_all_tokens(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Get list of ONLY words (no punct)\n",
    "word_list = get_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Get list of ONLY punct (no words)\n",
    "punct_list = get_punct(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "#4) WORD LENGTH\n",
    "average_word_list = []\n",
    "for comment in word_list:\n",
    "    average_word_list.append(average_word_length(comment))\n",
    "\n",
    "print(len(average_word_list))    \n",
    "    \n",
    "#Create DataFrame for Summary of Irony STATS\n",
    "summary= pd.DataFrame({\"Average Word Length\": average_word_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment Parsed</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Cola, costs, more, per, litre, than, petrol, ...</td>\n",
       "      <td>[Cola, costs, more, per, litre, than, petrol, ...</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Damn, .,   , I, ca, n't, believe, this, book,...</td>\n",
       "      <td>[Damn,   , I, ca, n't, believe, this, book, se...</td>\n",
       "      <td>[., ., ,, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(My, mother, -, in, -, law, watches, way, to, ...</td>\n",
       "      <td>[My, mother, in, law, watches, way, to, much, ...</td>\n",
       "      <td>[-, -, ,, ,, ,, ., ,, ., ,, \", ,, ,, !, !, \", .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Do, you, know, what, type, of, salt, was, use...</td>\n",
       "      <td>[Do, you, know, what, type, of, salt, was, use...</td>\n",
       "      <td>[?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Also, ,, I, 'm, pretty, sure, surveys, have, ...</td>\n",
       "      <td>[Also, I, 'm, pretty, sure, surveys, have, sho...</td>\n",
       "      <td>[,, ., ,, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Comment Parsed  \\\n",
       "0  (Cola, costs, more, per, litre, than, petrol, ...   \n",
       "1  (Damn, .,   , I, ca, n't, believe, this, book,...   \n",
       "2  (My, mother, -, in, -, law, watches, way, to, ...   \n",
       "3  (Do, you, know, what, type, of, salt, was, use...   \n",
       "4  (Also, ,, I, 'm, pretty, sure, surveys, have, ...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Cola, costs, more, per, litre, than, petrol, ...   \n",
       "1  [Damn,   , I, ca, n't, believe, this, book, se...   \n",
       "2  [My, mother, in, law, watches, way, to, much, ...   \n",
       "3  [Do, you, know, what, type, of, salt, was, use...   \n",
       "4  [Also, I, 'm, pretty, sure, surveys, have, sho...   \n",
       "\n",
       "                                        Punctuation  \n",
       "0                                               [.]  \n",
       "1                                      [., ., ,, .]  \n",
       "2  [-, -, ,, ,, ,, ., ,, ., ,, \", ,, ,, !, !, \", .]  \n",
       "3                                               [?]  \n",
       "4                                      [,, ., ,, .]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create df for total, full returns for irony\n",
    "total_val= pd.DataFrame({'Comment Parsed':tokens})\n",
    "total_val[\"Tokens\"] = word_list\n",
    "total_val[\"Punctuation\"] = punct_list\n",
    "total_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length\n",
       "0             4.555556                10.000000\n",
       "1             4.080000                 9.666667\n",
       "2             3.625000                27.200000\n",
       "3             3.666667                13.000000\n",
       "4             4.704545                24.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4) SENTENCE LENGTH\n",
    "average_sentence_list = []\n",
    "for x in tokens:\n",
    "    average_sentence_list.append(average_sent_length(x))\n",
    "\n",
    "#Add to Summary of Irony STATS df\n",
    "summary[\"Average Sentence Length\"] = average_sentence_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) /S SYMBOLS\n",
    "\n",
    "sarcfunc = []\n",
    "for x in tokens:\n",
    "    sarcfunc.append(check_sarcsymbol(x))\n",
    "\n",
    "\n",
    "sarcsymb_list = []        \n",
    "for l in sarcfunc:\n",
    "    if len(l) >= 1:\n",
    "        sarcsymb_list.append(l)\n",
    "    else:\n",
    "        sarcsymb_list.append([0])\n",
    "\n",
    "#Remove list layer \n",
    "sarcsymb_list = list(chain.from_iterable(sarcsymb_list))\n",
    "\n",
    "\n",
    "\n",
    "summary[\"Average '/s' symbol count\"] = sarcsymb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Average '/s' symbol count</th>\n",
       "      <th>Average Upper-case Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  Average '/s' symbol count  \\\n",
       "0             4.555556                10.000000                        0.0   \n",
       "1             4.080000                 9.666667                        0.0   \n",
       "2             3.625000                27.200000                        0.0   \n",
       "3             3.666667                13.000000                        0.0   \n",
       "4             4.704545                24.000000                        0.0   \n",
       "\n",
       "   Average Upper-case Words  \n",
       "0                  0.000000  \n",
       "1                  0.034483  \n",
       "2                  0.051471  \n",
       "3                  0.000000  \n",
       "4                  0.020833  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7) UPPER CASE WORDS (total)\n",
    "\n",
    "uppercase_list = []\n",
    "for b in tokens:\n",
    "    uppercase_list.append((count_uppercase(b)))\n",
    "    \n",
    "#Remove list layer \n",
    "uppercase_list = list(chain.from_iterable(uppercase_list))\n",
    "\n",
    "summary[\"Average Upper-case Words\"] = uppercase_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Average '/s' symbol count</th>\n",
       "      <th>Average Upper-case Words</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  Average '/s' symbol count  \\\n",
       "0             4.555556                10.000000                        0.0   \n",
       "1             4.080000                 9.666667                        0.0   \n",
       "2             3.625000                27.200000                        0.0   \n",
       "3             3.666667                13.000000                        0.0   \n",
       "4             4.704545                24.000000                        0.0   \n",
       "\n",
       "   Average Upper-case Words  Punctuation Richness  \n",
       "0                  0.000000                   6.0  \n",
       "1                  0.034483                  18.5  \n",
       "2                  0.051471                  84.0  \n",
       "3                  0.000000                   7.5  \n",
       "4                  0.020833                  28.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6) PUNCTUATION RICHNESS\n",
    "average_punct_list = get_punct_average(punct_list, tokens)\n",
    "\n",
    "summary[\"Punctuation Richness\"] = average_punct_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Average '/s' symbol count</th>\n",
       "      <th>Average Upper-case Words</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "      <th>Verb Lemma Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.132353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  Average '/s' symbol count  \\\n",
       "0             4.555556                10.000000                        0.0   \n",
       "1             4.080000                 9.666667                        0.0   \n",
       "2             3.625000                27.200000                        0.0   \n",
       "3             3.666667                13.000000                        0.0   \n",
       "4             4.704545                24.000000                        0.0   \n",
       "\n",
       "   Average Upper-case Words  Punctuation Richness  Verb Lemma Average  \n",
       "0                  0.000000                   6.0            0.100000  \n",
       "1                  0.034483                  18.5            0.241379  \n",
       "2                  0.051471                  84.0            0.132353  \n",
       "3                  0.000000                   7.5            0.307692  \n",
       "4                  0.020833                  28.0            0.187500  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9) AVERAGE NUMBER OF LEMMAS\n",
    "\n",
    "lemma_list = []\n",
    "for doc in tokens:\n",
    "    lemma_list.append(get_lemmas(doc))\n",
    "    \n",
    "summary[\"Verb Lemma Average\"] = lemma_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Average '/s' symbol count</th>\n",
       "      <th>Average Upper-case Words</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "      <th>Verb Lemma Average</th>\n",
       "      <th>Sentiment Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  Average '/s' symbol count  \\\n",
       "0             4.555556                10.000000                        0.0   \n",
       "1             4.080000                 9.666667                        0.0   \n",
       "2             3.625000                27.200000                        0.0   \n",
       "3             3.666667                13.000000                        0.0   \n",
       "4             4.704545                24.000000                        0.0   \n",
       "\n",
       "   Average Upper-case Words  Punctuation Richness  Verb Lemma Average  \\\n",
       "0                  0.000000                   6.0            0.100000   \n",
       "1                  0.034483                  18.5            0.241379   \n",
       "2                  0.051471                  84.0            0.132353   \n",
       "3                  0.000000                   7.5            0.307692   \n",
       "4                  0.020833                  28.0            0.187500   \n",
       "\n",
       "   Sentiment Classification  \n",
       "0                        -1  \n",
       "1                         1  \n",
       "2                        -1  \n",
       "3                         1  \n",
       "4                         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 SENTIMENT CLASSIFICATION\n",
    "#1 = positive, -1 = negative\n",
    "\n",
    "sentiment = get_sentiment(val_dict)\n",
    "\n",
    "summary[\"Sentiment Classification\"] = sentiment \n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>:</th>\n",
       "      <th>:)</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>[</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "      <th>–</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !         \"   #   %   &   '   (   )   *         , ...   :  :)   ;  \\\n",
       "0       NaN       NaN NaN NaN NaN NaN NaN NaN NaN       NaN ... NaN NaN NaN   \n",
       "1       NaN       NaN NaN NaN NaN NaN NaN NaN NaN  0.034483 ... NaN NaN NaN   \n",
       "2  0.014706  0.014706 NaN NaN NaN NaN NaN NaN NaN  0.051471 ... NaN NaN NaN   \n",
       "3       NaN       NaN NaN NaN NaN NaN NaN NaN NaN       NaN ... NaN NaN NaN   \n",
       "4       NaN       NaN NaN NaN NaN NaN NaN NaN NaN  0.041667 ... NaN NaN NaN   \n",
       "\n",
       "          ?   [   ]   _   –   “   ”  \n",
       "0       NaN NaN NaN NaN NaN NaN NaN  \n",
       "1       NaN NaN NaN NaN NaN NaN NaN  \n",
       "2       NaN NaN NaN NaN NaN NaN NaN  \n",
       "3  0.076923 NaN NaN NaN NaN NaN NaN  \n",
       "4       NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8) INDIVIDUAL PUNCTUATION AVERAGE\n",
    "\n",
    "average_indiv_punc_list = []\n",
    "for x in tokens:\n",
    "    average_indiv_punc_list.append(get_indiv_punct(x))\n",
    "\n",
    "\n",
    "summary_indiv_punct = pd.DataFrame(average_indiv_punc_list)\n",
    "summary_indiv_punct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ADJ       ADP       ADV     CCONJ       DET      INTJ      NOUN  \\\n",
       "0  0.100000  0.200000  0.200000       NaN       NaN       NaN  0.200000   \n",
       "1       NaN  0.068966  0.068966  0.034483  0.068966  0.034483  0.172414   \n",
       "2  0.073529  0.088235  0.029412  0.036765  0.088235       NaN  0.161765   \n",
       "3  0.076923  0.153846       NaN       NaN       NaN       NaN  0.307692   \n",
       "4  0.062500  0.125000  0.083333  0.041667  0.020833       NaN  0.187500   \n",
       "\n",
       "        NUM      PART      PRON     PROPN     PUNCT     SPACE       SYM  \\\n",
       "0       NaN       NaN       NaN  0.100000  0.100000       NaN       NaN   \n",
       "1       NaN       NaN  0.103448       NaN  0.137931  0.068966       NaN   \n",
       "2  0.014706  0.022059  0.088235  0.014706  0.117647  0.022059  0.007353   \n",
       "3       NaN       NaN  0.076923       NaN  0.076923       NaN       NaN   \n",
       "4       NaN  0.041667  0.062500       NaN  0.083333  0.020833       NaN   \n",
       "\n",
       "       VERB         X  \n",
       "0  0.100000       NaN  \n",
       "1  0.241379       NaN  \n",
       "2  0.227941  0.007353  \n",
       "3  0.307692       NaN  \n",
       "4  0.270833       NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7) WORD TYPE AVERAGE \n",
    "\n",
    "average_wordtype_list = []\n",
    "for comment in tokens:\n",
    "    average_wordtype_list.append(relative_count_wordtypes(comment))\n",
    "\n",
    "summary_wordtypedf = pd.DataFrame(average_wordtype_list)\n",
    "summary_wordtypedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>NORP</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDINAL      DATE  EVENT  FAC  GPE  LAW  LOC     MONEY  NORP  ORDINAL  \\\n",
       "0  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "1  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "2  0.007353  0.014706    0.0  0.0  0.0  0.0  0.0  0.007353   0.0      0.0   \n",
       "3  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "4  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "\n",
       "        ORG  PERCENT  PERSON  PRODUCT  QUANTITY  TIME  WORK_OF_ART  \n",
       "0  0.000000      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "1  0.000000      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "2  0.007353      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "3  0.000000      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "4  0.020833      0.0     0.0      0.0       0.0   0.0          0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10) NAMED ENTITIES AVERAGE\n",
    "named_entity_list = []\n",
    "for comment in tokens:\n",
    "    named_entity_list.append(get_entities(comment))\n",
    "    \n",
    "summary_named_entity = pd.DataFrame(named_entity_list)\n",
    "\n",
    "summary_named_entity = summary_named_entity.replace(np.nan, 0) \n",
    "summary_named_entity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Additional Functions (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Classification\n",
    "\n",
    "Steps:\n",
    "- (1) Import Master DF ###(1) GENERAL\n",
    "- (2) Get Results for each comparison using classification function (1) Ir, (2) Non-ir\n",
    "- (3) Create PredictorDF for (1) Ironic, (2) Non-ironic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''''''''''''''''''''''''''''''\n",
    "- (4) Import Master DF ###(2) POS\n",
    "- (5) Get Results for each comparison using classification function (1) Ir, (2) Non-ir\n",
    "- (6) Add to each PredictorDF for (1) Ironic, (2) Non-ironic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''''''''''''''''''''''''''''''\n",
    "- (7) Import Master DF ###(3) NAMED ENTITY\n",
    "- Repeat steps 5 & 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''''''''''''''''''''''''''''''\n",
    "- (8) Import Master DF ###(4) PUNCTUATION\n",
    "- Repeat steps 5 & 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Average '/s' symbol count</th>\n",
       "      <th>Average Upper-case Words</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "      <th>Verb Lemma Average</th>\n",
       "      <th>Sentiment Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic Comments</td>\n",
       "      <td>4.304183</td>\n",
       "      <td>14.261968</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.02535</td>\n",
       "      <td>20.927649</td>\n",
       "      <td>0.154378</td>\n",
       "      <td>0.405685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic Comments</td>\n",
       "      <td>4.411010</td>\n",
       "      <td>15.805244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02346</td>\n",
       "      <td>36.150972</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>0.455476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Class  Average Word Length  Average Sentence Length  \\\n",
       "0      Ironic Comments             4.304183                14.261968   \n",
       "1  Non-ironic Comments             4.411010                15.805244   \n",
       "\n",
       "   Average '/s' symbol count  Average Upper-case Words  Punctuation Richness  \\\n",
       "0                   0.000783                   0.02535             20.927649   \n",
       "1                   0.000000                   0.02346             36.150972   \n",
       "\n",
       "   Verb Lemma Average  Sentiment Classification  \n",
       "0            0.154378                  0.405685  \n",
       "1            0.146618                  0.455476  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####(1)\n",
    "#import GENERAL summary table\n",
    "master_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_general.csv\"\n",
    "mastergeneral_df = pd.read_csv(master_filename)\n",
    "mastergeneral_df.head()\n",
    "\n",
    "mastergeneral_df = mastergeneral_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})\n",
    "\n",
    "mastergeneral_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "ironic_average_word_length = get_classification_ironic(mastergeneral_df, summary, 1, 0, 0.8)\n",
    "ironic_average_sent_length= get_classification_ironic(mastergeneral_df, summary, 2, 1, 1)\n",
    "ironic_average_sarcsymb= get_classification_ironic(mastergeneral_df, summary, 3, 2, 7)\n",
    "ironic_average_uppercase = get_classification_ironic(mastergeneral_df, summary, 4, 3, 2)\n",
    "ironic_punct_richness = get_classification_ironic(mastergeneral_df, summary, 5, 4, 2)\n",
    "# ironic_average_verblemma = get_classification_ironic(mastergeneral_df, summary, 6, 5, 1)\n",
    "# ironic_average_sentiment = get_classification_ironic(mastergeneral_df, summary, 7, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.018265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.052241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.050701\n",
       "1     0.179346         4.595301    4.855297      0.005481   0.018265\n",
       "2     0.543346        12.938032  126.144703      0.005481   0.052241\n",
       "3     0.510013         1.261968   26.855297      0.005481   0.050701\n",
       "4     0.320290         9.738032   14.144703      0.005481   0.009034"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IRONIC\n",
    "#Create PREDICTOR DATAFRAME with classifications (all features)\n",
    "\n",
    "ironic_predictor_df = pd.DataFrame(ironic_average_word_length)\n",
    "ironic_predictor_df.columns = ['WORD LENGTH'] + ironic_predictor_df.columns.tolist()[1:]\n",
    "\n",
    "ironic_predictor_df[\"SENTENCE LENGTH\"] = ironic_average_sent_length\n",
    "ironic_predictor_df[\"PUNCT RICH\"] = ironic_punct_richness\n",
    "ironic_predictor_df[\"SARC SYMB /S\"] = ironic_average_sarcsymb\n",
    "ironic_predictor_df[\"UPPERCASE\"] = ironic_average_uppercase\n",
    "# ironic_predictor_df[\"Verb Lemma Average\"] = ironic_average_verblemma\n",
    "# ironic_predictor_df[\"Sentiment Classification\"] = ironic_average_sentiment\n",
    "\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON-IRONIC\n",
    "non_ironic_average_word_length = get_classification_non_ironic(mastergeneral_df, summary, 1, 0, 0.8)\n",
    "non_ironic_average_sent_length= get_classification_non_ironic(mastergeneral_df, summary, 2, 1, 1)\n",
    "non_ironic_average_sarcsymb= get_classification_non_ironic(mastergeneral_df, summary, 3, 2, 7)\n",
    "non_ironic_average_uppercase = get_classification_non_ironic(mastergeneral_df, summary, 4, 4, 2)\n",
    "non_ironic_punct_richness = get_classification_non_ironic(mastergeneral_df, summary, 5, 3, 2)\n",
    "# non_ironic_average_verblemma = get_classification_non_ironic(mastergeneral_df, summary, 6, 5, 1)\n",
    "# non_ironic_average_sentiment = get_classification_non_ironic(mastergeneral_df, summary, 7, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>11.953081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.232979</td>\n",
       "      <td>36.953081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.199004</td>\n",
       "      <td>167.953081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>14.953081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.260278</td>\n",
       "      <td>55.953081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH   UPPERCASE\n",
       "0     0.115636         5.805244           0.0   72.301945   11.953081\n",
       "1     0.264808         6.138577           0.0   72.232979   36.953081\n",
       "2     0.628808        11.394756           0.0   72.199004  167.953081\n",
       "3     0.595475         2.805244           0.0   72.301945   14.953081\n",
       "4     0.234828         8.194756           0.0   72.260278   55.953081"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NON-IRONIC\n",
    "#Create PREDICTOR DATAFRAME with classifications (all features)\n",
    "\n",
    "non_ironic_predictor_df = pd.DataFrame(non_ironic_average_word_length)\n",
    "non_ironic_predictor_df.columns = ['WORD LENGTH'] + non_ironic_predictor_df.columns.tolist()[1:]\n",
    "\n",
    "non_ironic_predictor_df[\"SENTENCE LENGTH\"] = non_ironic_average_sent_length\n",
    "non_ironic_predictor_df[\"SARC SYMB /S\"] = non_ironic_average_sarcsymb\n",
    "non_ironic_predictor_df[\"PUNCT RICH\"] = non_ironic_punct_richness\n",
    "non_ironic_predictor_df[\"UPPERCASE\"] = non_ironic_average_uppercase\n",
    "# non_ironic_predictor_df[\"Verb Lemma Average\"] = non_ironic_average_verblemma\n",
    "# non_ironic_predictor_df[\"Sentiment Classification\"] = non_ironic_average_sentiment\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic</td>\n",
       "      <td>0.085070</td>\n",
       "      <td>0.078270</td>\n",
       "      <td>0.064795</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.073488</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.164352</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.058805</td>\n",
       "      <td>0.145819</td>\n",
       "      <td>0.031440</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.174846</td>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic</td>\n",
       "      <td>0.080089</td>\n",
       "      <td>0.083053</td>\n",
       "      <td>0.070846</td>\n",
       "      <td>0.023582</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.158435</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.043878</td>\n",
       "      <td>0.141197</td>\n",
       "      <td>0.032398</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.180089</td>\n",
       "      <td>0.000810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       ADJ       ADP       ADV     CCONJ       DET      INTJ  \\\n",
       "0      Ironic  0.085070  0.078270  0.064795  0.017629  0.073488  0.007642   \n",
       "1  Non-ironic  0.080089  0.083053  0.070846  0.023582  0.081000  0.005765   \n",
       "\n",
       "       NOUN       NUM      PART      PRON     PROPN     PUNCT     SPACE  \\\n",
       "0  0.164352  0.007932  0.022388  0.063109  0.058805  0.145819  0.031440   \n",
       "1  0.158435  0.009828  0.022023  0.061435  0.043878  0.141197  0.032398   \n",
       "\n",
       "        SYM      VERB         X  \n",
       "0  0.004067  0.174846  0.000348  \n",
       "1  0.005573  0.180089  0.000810  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####(2)\n",
    "#import POS summary table\n",
    "master_wordtype_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_wordtype.csv\"\n",
    "masterwordtype_df = pd.read_csv(master_wordtype_filename)\n",
    "masterwordtype_df.head()\n",
    "\n",
    "masterwordtype_df = masterwordtype_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"}) \n",
    "masterwordtype_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. PRON, PROPN, NOUN\n",
    "\n",
    "# ironic_PRON_dist= get_classification_ironic(masterwordtype_df, summary_wordtypedf, 10, 9, 1)\n",
    "ironic_PROPN_dist_length= get_classification_ironic(masterwordtype_df, summary_wordtypedf, 11, 10, 1)\n",
    "# ironic_NOUN_dist = get_classification_ironic(masterwordtype_df, summary_wordtypedf, 7, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.041195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.044099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE     PROPN\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.050701  0.041195\n",
       "1     0.179346         4.595301    4.855297      0.005481   0.018265  0.000000\n",
       "2     0.543346        12.938032  126.144703      0.005481   0.052241  0.044099\n",
       "3     0.510013         1.261968   26.855297      0.005481   0.050701  0.000000\n",
       "4     0.320290         9.738032   14.144703      0.005481   0.009034  0.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "# ironic_predictor_df[\"PRON\"] = ironic_PRON_dist\n",
    "ironic_predictor_df[\"PROPN\"] = ironic_PROPN_dist_length\n",
    "# ironic_predictor_df[\"NOUN\"] = ironic_NOUN_dist\n",
    "ironic_predictor_df = ironic_predictor_df.replace(np.nan, 0)\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON-IRONIC\n",
    "#E.g. PRON, PROPN, NOUN\n",
    "\n",
    "# nonironic_PRON_dist= get_classification_non_ironic(masterwordtype_df, summary_wordtypedf, 10, 9, 1)\n",
    "nonironic_PROPN_dist_length= get_classification_non_ironic(masterwordtype_df, summary_wordtypedf, 11, 10, 1)\n",
    "# nonironic_NOUN_dist = get_classification_non_ironic(masterwordtype_df, summary_wordtypedf, 7, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>11.953081</td>\n",
       "      <td>0.056122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.232979</td>\n",
       "      <td>36.953081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.199004</td>\n",
       "      <td>167.953081</td>\n",
       "      <td>0.029172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>14.953081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.260278</td>\n",
       "      <td>55.953081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH   UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   72.301945   11.953081   \n",
       "1     0.264808         6.138577           0.0   72.232979   36.953081   \n",
       "2     0.628808        11.394756           0.0   72.199004  167.953081   \n",
       "3     0.595475         2.805244           0.0   72.301945   14.953081   \n",
       "4     0.234828         8.194756           0.0   72.260278   55.953081   \n",
       "\n",
       "      PROPN  \n",
       "0  0.056122  \n",
       "1       NaN  \n",
       "2  0.029172  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to NON-IRONIC PREDICTOR DATAFRAME\n",
    "# non_ironic_predictor_df[\"PRON\"] = nonironic_PRON_dist\n",
    "non_ironic_predictor_df[\"PROPN\"] = nonironic_PROPN_dist_length\n",
    "# non_ironic_predictor_df[\"NOUN\"] = nonironic_NOUN_dist\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>NORP</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CARDINAL      DATE     EVENT       FAC       GPE  LANGUAGE  \\\n",
       "0      Ironic  0.004144  0.003744  0.000066  0.000008  0.006832  0.000000   \n",
       "1  Non-ironic  0.004955  0.004464  0.000106  0.000078  0.004595  0.000044   \n",
       "\n",
       "        LAW       LOC     MONEY      NORP   ORDINAL       ORG   PERCENT  \\\n",
       "0  0.000155  0.000820  0.001215  0.008090  0.000965  0.013508  0.001186   \n",
       "1  0.000126  0.000499  0.000849  0.006177  0.000913  0.008829  0.000773   \n",
       "\n",
       "     PERSON   PRODUCT  QUANTITY      TIME  WORK_OF_ART  \n",
       "0  0.010383  0.000144  0.000008  0.000418     0.000280  \n",
       "1  0.009020  0.000049  0.000225  0.000444     0.000677  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####(3)\n",
    "#import NER summary table\n",
    "master_ner_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_namedentity.csv\"\n",
    "masterentity_df = pd.read_csv(master_ner_filename)\n",
    "masterentity_df.head()\n",
    "\n",
    "masterentity_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})\n",
    "masterentity_df = masterentity_df.replace(np.nan, 0)\n",
    "masterentity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. PERSON, LOC, GPE, LANGUAGE (none)\n",
    "\n",
    "ironic_PERSON_dist= get_classification_ironic(masterentity_df, summary_named_entity, 14, 13, 4)\n",
    "# ironic_LOC_dist_length= get_classification_ironic(masterentity_df, summary_named_entity, 8, 7, 1)\n",
    "ironic_GPE_dist = get_classification_ironic(masterentity_df, summary_named_entity, 5, 4, 5)\n",
    "# ironic_LANGUAGE_dist = get_classification_ironic(masterentity_df, summary_named_entity, 6, 5, 1)\n",
    "\n",
    "ironic_ORG_dist= get_classification_ironic(masterentity_df, summary_named_entity, 12, 11, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>GPE</th>\n",
       "      <th>ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE  \\\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.050701   \n",
       "1     0.179346         4.595301    4.855297      0.005481   0.018265   \n",
       "2     0.543346        12.938032  126.144703      0.005481   0.052241   \n",
       "3     0.510013         1.261968   26.855297      0.005481   0.050701   \n",
       "4     0.320290         9.738032   14.144703      0.005481   0.009034   \n",
       "\n",
       "      PROPN    PERSON      GPE       ORG  \n",
       "0  0.041195  0.041533  0.03416  0.094556  \n",
       "1  0.000000  0.041533  0.03416  0.094556  \n",
       "2  0.044099  0.041533  0.03416  0.094556  \n",
       "3  0.000000  0.041533  0.03416  0.094556  \n",
       "4  0.000000  0.041533  0.03416  0.094556  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "ironic_predictor_df[\"PERSON\"] = ironic_PERSON_dist\n",
    "# ironic_predictor_df[\"LOC\"] = ironic_LOC_dist_length\n",
    "ironic_predictor_df[\"GPE\"] = ironic_GPE_dist\n",
    "# ironic_predictor_df[\"LANGUAGE\"] = ironic_LANGUAGE_dist\n",
    "ironic_predictor_df[\"ORG\"] = ironic_ORG_dist\n",
    "\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON- IRONIC\n",
    "#E.g. PERSON, LOC, GPE, LANGUAGE (none)\n",
    "\n",
    "nonironic_PERSON_dist= get_classification_non_ironic(masterentity_df, summary_named_entity, 14, 13, 4)\n",
    "# nonironic_LOC_dist= get_classification_non_ironic(masterentity_df, summary_named_entity, 8, 7, 1)\n",
    "nonironic_GPE_dist = get_classification_non_ironic(masterentity_df, summary_named_entity, 5, 4, 5)\n",
    "# nonironic_LANGUAGE_dist = get_classification_non_ironic(masterentity_df, summary_named_entity, 6, 5, 1)\n",
    "nonironic_ORG_dist = get_classification_non_ironic(masterentity_df, summary_named_entity, 12, 11, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>GPE</th>\n",
       "      <th>ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>11.953081</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.232979</td>\n",
       "      <td>36.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.199004</td>\n",
       "      <td>167.953081</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>14.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.260278</td>\n",
       "      <td>55.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH   UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   72.301945   11.953081   \n",
       "1     0.264808         6.138577           0.0   72.232979   36.953081   \n",
       "2     0.628808        11.394756           0.0   72.199004  167.953081   \n",
       "3     0.595475         2.805244           0.0   72.301945   14.953081   \n",
       "4     0.234828         8.194756           0.0   72.260278   55.953081   \n",
       "\n",
       "      PROPN    PERSON       GPE     ORG  \n",
       "0  0.056122  0.036079  0.022975  0.0618  \n",
       "1       NaN  0.036079  0.022975  0.0618  \n",
       "2  0.029172  0.036079  0.022975  0.0618  \n",
       "3       NaN  0.036079  0.022975  0.0618  \n",
       "4       NaN  0.036079  0.022975  0.0618  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to NON-IRONIC PREDICTOR DATAFRAME\n",
    "non_ironic_predictor_df[\"PERSON\"] = nonironic_PERSON_dist\n",
    "# non_ironic_predictor_df[\"LOC\"] = nonironic_LOC_dist\n",
    "non_ironic_predictor_df[\"GPE\"] = nonironic_GPE_dist\n",
    "# non_ironic_predictor_df[\"LANGUAGE\"] = nonironic_LANGUAGE_dist\n",
    "non_ironic_predictor_df[\"ORG\"] = nonironic_ORG_dist\n",
    "\n",
    "\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>\")</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>---</th>\n",
       "      <th>----------</th>\n",
       "      <th>.</th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>....</th>\n",
       "      <th>.....</th>\n",
       "      <th>......</th>\n",
       "      <th>.......</th>\n",
       "      <th>/</th>\n",
       "      <th>:</th>\n",
       "      <th>:(</th>\n",
       "      <th>:)</th>\n",
       "      <th>:-)</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>[</th>\n",
       "      <th>\\</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "      <th>§</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.027248</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.059713</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         !         \"        \")         #         %         &  \\\n",
       "0      Ironic  0.009634  0.009414  0.000008  0.000000  0.001100  0.001022   \n",
       "1  Non-ironic  0.003882  0.008162  0.000000  0.000028  0.000592  0.001495   \n",
       "\n",
       "          '         (         )         *         ,         -        --  \\\n",
       "0  0.001277  0.000581  0.000797  0.005973  0.027248  0.005296  0.000122   \n",
       "1  0.001599  0.002037  0.003004  0.003820  0.024176  0.006119  0.000130   \n",
       "\n",
       "       ---  ----------         .        ..       ...      ....     .....  \\\n",
       "0  0.00000    0.000000  0.058454  0.000622  0.003805  0.001050  0.000000   \n",
       "1  0.00001    0.000006  0.059713  0.000438  0.003519  0.000866  0.000285   \n",
       "\n",
       "     ......  .......         /         :        :(        :)       :-)  \\\n",
       "0  0.000000  0.00000  0.002371  0.002534  0.000103  0.000161  0.000000   \n",
       "1  0.000053  0.00001  0.004311  0.001178  0.000099  0.000154  0.000025   \n",
       "\n",
       "          ;         ?         [         \\         ]         _         §  \\\n",
       "0  0.000786  0.014821  0.000490  0.000083  0.000421  0.000049  0.000000   \n",
       "1  0.001531  0.010570  0.004692  0.000000  0.003895  0.000011  0.000012   \n",
       "\n",
       "          –         —         ‘         “         ”  \n",
       "0  0.000008  0.000076  0.000008  0.000287  0.000315  \n",
       "1  0.000012  0.000028  0.000017  0.000110  0.000129  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####(4)\n",
    "#import PUNCTUATION summary table\n",
    "master_punct_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_puncttype.csv\"\n",
    "masterpunct_df = pd.read_csv(master_punct_filename)\n",
    "masterpunct_df.head()\n",
    "\n",
    "masterpunct_df = masterpunct_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})\n",
    "pd.options.display.max_columns = 40\n",
    "masterpunct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. !, ', *, :( \n",
    "\n",
    "ironic_exclam_dist= get_classification_ironic(masterentity_df, summary_indiv_punct, 1, 0, 8)\n",
    "# # ironic_apost_dist_length= get_classification_ironic(masterentity_df, summary_indiv_punct, 7, 6, 1)\n",
    "# ironic_star_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 10, 9, 1)\n",
    "# ironic_quest_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 29, 28, 1)\n",
    "# ironic_sademoji_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 25, 24, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "ironic_predictor_df[\"!\"] = ironic_exclam_dist\n",
    "# ironic_predictor_df[\"'\"] = ironic_apost_dist_length\n",
    "# ironic_predictor_df[\"*\"] = ironic_star_dist\n",
    "# # ironic_predictor_df[\"LANGUAGE\"] = ironic_LANGUAGE_dist\n",
    "# ironic_predictor_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON- IRONIC\n",
    "#E.g. !, ', *, :( \n",
    "\n",
    "nonironic_exclam_dist= get_classification_non_ironic(masterentity_df, summary_indiv_punct, 1, 0, 8)\n",
    "# nonironic_apost_dist_length= get_classification_non_ironic(masterentity_df, summary_indiv_punct, 7, 6, 1)\n",
    "# nonironic_star_dist = get_classification_non_ironic(masterentity_df, summary_indiv_punct, 10, 9, 1)\n",
    "# # ironic_sademoji_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 25, 24, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>GPE</th>\n",
       "      <th>ORG</th>\n",
       "      <th>!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>11.953081</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.232979</td>\n",
       "      <td>36.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.199004</td>\n",
       "      <td>167.953081</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.078006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>14.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.260278</td>\n",
       "      <td>55.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH   UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   72.301945   11.953081   \n",
       "1     0.264808         6.138577           0.0   72.232979   36.953081   \n",
       "2     0.628808        11.394756           0.0   72.199004  167.953081   \n",
       "3     0.595475         2.805244           0.0   72.301945   14.953081   \n",
       "4     0.234828         8.194756           0.0   72.260278   55.953081   \n",
       "\n",
       "      PROPN    PERSON       GPE     ORG         !  \n",
       "0  0.056122  0.036079  0.022975  0.0618       NaN  \n",
       "1       NaN  0.036079  0.022975  0.0618       NaN  \n",
       "2  0.029172  0.036079  0.022975  0.0618  0.078006  \n",
       "3       NaN  0.036079  0.022975  0.0618       NaN  \n",
       "4       NaN  0.036079  0.022975  0.0618       NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "non_ironic_predictor_df[\"!\"] = nonironic_exclam_dist\n",
    "# non_ironic_predictor_df[\"'\"] = nonironic_apost_dist_length\n",
    "# non_ironic_predictor_df[\"*\"] = nonironic_star_dist\n",
    "# # ironic_predictor_df[\"LANGUAGE\"] = ironic_LANGUAGE_dist\n",
    "# non_ironic_predictor_df = non_ironic_predictor_df.replace(np.nan, 0)\n",
    "non_ironic_predictor_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>GPE</th>\n",
       "      <th>ORG</th>\n",
       "      <th>!</th>\n",
       "      <th>Feature Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.585988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.823938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>0.084494</td>\n",
       "      <td>139.982644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.853707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.387788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE  \\\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.050701   \n",
       "1     0.179346         4.595301    4.855297      0.005481   0.018265   \n",
       "2     0.543346        12.938032  126.144703      0.005481   0.052241   \n",
       "3     0.510013         1.261968   26.855297      0.005481   0.050701   \n",
       "4     0.320290         9.738032   14.144703      0.005481   0.009034   \n",
       "\n",
       "      PROPN    PERSON      GPE       ORG         !  Feature Weight  \n",
       "0  0.041195  0.041533  0.03416  0.094556       NaN       34.585988  \n",
       "1  0.000000  0.041533  0.03416  0.094556       NaN        9.823938  \n",
       "2  0.044099  0.041533  0.03416  0.094556  0.084494      139.982644  \n",
       "3  0.000000  0.041533  0.03416  0.094556       NaN       28.853707  \n",
       "4  0.000000  0.041533  0.03416  0.094556       NaN       24.387788  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the sum of all features for each comment\n",
    "ironic_feature_prediction = ironic_predictor_df.sum(axis=1)\n",
    "\n",
    "#add final column to ironic predictor df with feature totals\n",
    "ironic_predictor_df[\"Feature Weight\"] = ironic_predictor_df.sum(axis=1)\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>GPE</th>\n",
       "      <th>ORG</th>\n",
       "      <th>!</th>\n",
       "      <th>Feature Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>11.953081</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.352882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.232979</td>\n",
       "      <td>36.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.199004</td>\n",
       "      <td>167.953081</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.078006</td>\n",
       "      <td>252.403680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.301945</td>\n",
       "      <td>14.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.776599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.260278</td>\n",
       "      <td>55.953081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.763797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH   UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   72.301945   11.953081   \n",
       "1     0.264808         6.138577           0.0   72.232979   36.953081   \n",
       "2     0.628808        11.394756           0.0   72.199004  167.953081   \n",
       "3     0.595475         2.805244           0.0   72.301945   14.953081   \n",
       "4     0.234828         8.194756           0.0   72.260278   55.953081   \n",
       "\n",
       "      PROPN    PERSON       GPE     ORG         !  Feature Weight  \n",
       "0  0.056122  0.036079  0.022975  0.0618       NaN       90.352882  \n",
       "1       NaN  0.036079  0.022975  0.0618       NaN      115.710300  \n",
       "2  0.029172  0.036079  0.022975  0.0618  0.078006      252.403680  \n",
       "3       NaN  0.036079  0.022975  0.0618       NaN       90.776599  \n",
       "4       NaN  0.036079  0.022975  0.0618       NaN      136.763797  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the sum of all features for each comment\n",
    "non_ironic_feature_prediction = non_ironic_predictor_df.sum(axis=1)\n",
    "\n",
    "#add final column to ironic predictor df with feature totals\n",
    "non_ironic_predictor_df[\"Feature Weight\"] = non_ironic_predictor_df.sum(axis=1)\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-ironic Feature Result</th>\n",
       "      <th>Ironic Feature Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.352882</td>\n",
       "      <td>34.585988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.710300</td>\n",
       "      <td>9.823938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252.403680</td>\n",
       "      <td>139.982644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.776599</td>\n",
       "      <td>28.853707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136.763797</td>\n",
       "      <td>24.387788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Non-ironic Feature Result  Ironic Feature Result\n",
       "0                  90.352882              34.585988\n",
       "1                 115.710300               9.823938\n",
       "2                 252.403680             139.982644\n",
       "3                  90.776599              28.853707\n",
       "4                 136.763797              24.387788"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create final df with final predicitons\n",
    "final_predictordf = pd.DataFrame(non_ironic_feature_prediction)\n",
    "\n",
    "final_predictordf.columns = [\"Non-ironic Feature Result\"] + final_predictordf.columns.tolist()[1:]\n",
    "final_predictordf[\"Ironic Feature Result\"] = ironic_feature_prediction\n",
    "\n",
    "final_predictordf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Comment_Text    object\n",
       "Label            int64\n",
       "Prediction       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction = final_predicition_results(final_predictordf)\n",
    "\n",
    "val[\"Prediction\"] = final_prediction\n",
    "print(len(val))\n",
    "\n",
    "# #change order of columns (so label and prediction side by side)\n",
    "val = val[['Comment_Text','Label','Prediction']]\n",
    "\n",
    "val.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_result_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/classification_results.csv\"\n",
    "\n",
    "val.to_csv(classification_result_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24102564102564103\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy(val)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
