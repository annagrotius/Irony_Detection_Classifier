{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import/install all packages at the top\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections:\n",
    "\n",
    "# (1) Import dataset and split\n",
    "\n",
    "# (2) Functions\n",
    "\n",
    "# (3) Validation Testing (obtain stats ready for comparison)\n",
    "------- get stats and create summary df\n",
    "- (3.1) Average Word Count\n",
    "- (3.2) Average Sentence Count\n",
    "- (3.3) Punctuation Richness\n",
    "- (3.4) Sarcasm Symbol\n",
    "- (3.5) Upper-case Words\n",
    "\n",
    "- (3.6) Individual Punctuation Count\n",
    "- (3.7) Word Type Count\n",
    "- (3.8) Named Entity Count\n",
    "\n",
    "# (4) Additional Functions for Classification\n",
    "# (5) Classification\n",
    "# (5) Classification Results\n",
    "# (6) Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Import and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Read file as DF with PANDAS (for better visualisation)\n",
    "filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/irony-labeled.csv\"\n",
    "gold_label = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the columns\n",
    "gold_label.columns = [\"Comment_Text\", \"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to get two DFs (prep for split)\n",
    "\n",
    "y = gold_label[\"Comment_Text\"]\n",
    "x = gold_label[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into TEST and TRAIN sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=43)\n",
    "\n",
    "#Split the TRAIN set again to get VALIDATION set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOIN the series together to get final splits as DFs\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "val = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data contains 47 IRONIC comments\n",
      "Training data contains 148 NON- IRONIC comments\n"
     ]
    }
   ],
   "source": [
    "#Check number of comments labelled as ironic vs non-ironic\n",
    "ironic_val = val[val[\"Label\"] == 1]\n",
    "nonironic_val = val[val[\"Label\"] == -1]\n",
    "\n",
    "print(f\"Training data contains {len(ironic_val)} IRONIC comments\")\n",
    "print(f\"Training data contains {len(nonironic_val)} NON- IRONIC comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "#Convert TEST(validation) set into a dictionary\n",
    "val_dict = val.set_index(val.index).T.to_dict()\n",
    "\n",
    "print(len(val_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) FUNCTIONS - to be saved to python script as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tokens(test_dict):\n",
    "    \"\"\"Input dictionary and return list of comments as SpaCy docs\"\"\"\n",
    "    comment_list = []\n",
    "    for comment_index, label in test_dict.items():\n",
    "        for key in label:\n",
    "            text = label[key]\n",
    "            if type(text) == str:\n",
    "                comment_list.append(nlp(text))\n",
    "    return comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(listx):\n",
    "    \"\"\"Take a list (already parsed through SpaCy) remove punctuation and return list of word tokens\"\"\"\n",
    "    ir_clean_docs = [] #remove punctuation\n",
    "\n",
    "    for x in listx:\n",
    "        clean_list = []\n",
    "        for y in x:\n",
    "            if y.pos_ != 'PUNCT':\n",
    "                clean_list.append(y)\n",
    "        ir_clean_docs.append(clean_list)\n",
    "    return ir_clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct(listx):\n",
    "    \"\"\"Take a list (already parsed through spacy), remove words and return list of punctuation ONLY\"\"\"\n",
    "    ir_punct = [] #only punctuation\n",
    "\n",
    "    for x in listx:\n",
    "        clean_list = []\n",
    "        for y in x:\n",
    "            if y.pos_ == 'PUNCT':\n",
    "                clean_list.append(y)\n",
    "        ir_punct.append(clean_list)\n",
    "    return ir_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(doc):\n",
    "    \"\"\"Take doc and return average word length\"\"\"\n",
    "    for token in doc:\n",
    "        word = token.text\n",
    "        average_word_length = sum(len(word) for word in doc) / len(doc)\n",
    "    return(average_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sent_length(doc):\n",
    "    \"\"\"Take doc and return average sentence length\"\"\"\n",
    "    sent_list = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        len_sent = len(sent)\n",
    "        sent_list.append(len_sent)\n",
    "\n",
    "    total = sum(sent_list)\n",
    "    leng = len(sent_list)\n",
    "\n",
    "    average_sent_length = total / leng\n",
    "    return(average_sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_count_wordtypes(doc):\n",
    "    \"\"\"Return relative count average for all word types i.e. nouns, pronouns, verbs etc with word type as key and average as value\"\"\"\n",
    "    pos_tags = []\n",
    "    for token in doc:\n",
    "        pos_tags.append(token.pos_)\n",
    "    counting = Counter(pos_tags) #returns dictionary with whole count for each word type in doc\n",
    "    \n",
    "    leng = len(doc) #overall length of doc (no. of tokens)\n",
    "    new_dict = {}\n",
    "    \n",
    "    for key, value in counting.items(): #iterate over entire dict\n",
    "        new_dict[key] = value/ leng\n",
    "            \n",
    "            \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sarcsymbol(doc):\n",
    "    \"\"\"Take a list of comments (parsed through SpaCy); return list with average number of \"/s\" symbols per comment [Reddit \"/s\" = sarcasm]\"\"\"\n",
    "    sarcsymb = []\n",
    "    leng = len(doc) \n",
    "    h = 1\n",
    "    \n",
    "    for x in doc: \n",
    "        if x.text == \"/s\" or x.text == \"/sarcasm\" or x.text == \"/sarc\":\n",
    "            sarcsymb.append(h/leng) \n",
    "        else:\n",
    "            pass\n",
    "               \n",
    "    return sarcsymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct_average(punctuation_list, token_comment_list):\n",
    "    \"\"\"Take preprocessed list of punctuation and full token list (MUST be of equal length); \n",
    "    Returns list of the average for ALL punctuation (based on number overall of tokens)\n",
    "    for each comment\"\"\" \n",
    "\n",
    "    punct_count = []\n",
    "    for comment in punctuation_list:\n",
    "        punct_count.append(len(comment))\n",
    "\n",
    "    len_comment = []\n",
    "    for comment in token_comment_list:\n",
    "        len_comment.append(len(comment))\n",
    "    \n",
    "    punct_count, len_comment = np.array(punct_count), np.array(len_comment) \n",
    "    averages = punct_count + len_comment/2\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indiv_punct(doc):\n",
    "    \"\"\"Return relative count average for all word types i.e. nouns, pronouns, verbs etc with word type as key and average as value\"\"\"\n",
    "    punc_tags = []\n",
    "    for token in doc:\n",
    "        if token.is_punct:\n",
    "            punc_tags.append(token)\n",
    "            \n",
    "    \n",
    "    #make each a string so not multiple keys with same vaues\n",
    "    punc_tags = [str(punc) for punc in punc_tags]\n",
    "           \n",
    "\n",
    "    punc_tag_dict = Counter(punc_tags) #returns dictionary with whole count for each word type in doc\n",
    "    \n",
    "    leng = len(doc) #overall length of doc (no. of tokens)\n",
    "    new_dict = {}\n",
    "    \n",
    "    for key, value in punc_tag_dict.items(): #iterate over entire dict\n",
    "        new_dict[key] = value/ leng\n",
    "            \n",
    "    final_dict = dict(new_dict)\n",
    "            \n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uppercase(doc):\n",
    "    \"\"\"Take nlp doc and return the average number of fully uppercase words for each comment as a list\"\"\"\n",
    "    new_list = []\n",
    "    \n",
    "    leng = len(doc)\n",
    "    for token in doc:\n",
    "        if token.is_upper == True:\n",
    "            new_list.append(token)\n",
    "            \n",
    "    counting = Counter(new_list)\n",
    "    my_dict = dict(counting)\n",
    "    \n",
    "    upper_count_avg = []\n",
    "\n",
    "    x = sum(my_dict.values())\n",
    "    upper_count_avg.append(x/leng)\n",
    "    \n",
    "    return upper_count_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(doc):\n",
    "    \"\"\"Take nlp doc and return a dictionary with key as ent.labe_ and value as the average number\"\"\"\n",
    "    entity = []\n",
    "    for token in doc.ents:\n",
    "        entity.append(token.label_)\n",
    "\n",
    "    new_dict = Counter(entity)\n",
    "    leng = len(doc)\n",
    "    \n",
    "    for key, value in new_dict.items():\n",
    "        new_dict[key] = value / leng\n",
    "        \n",
    "    ent_dict = dict(new_dict)\n",
    "    \n",
    "    return ent_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Validation Tetsing\n",
    "- Obtain all statistics (based on training) ready for comparison in next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) GET ALL TOKENS\n",
    "tokens = get_all_tokens(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Get list of ONLY words (no punct)\n",
    "word_list = get_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Get list of ONLY punct (no words)\n",
    "punct_list = get_punct(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "#4) WORD LENGTH\n",
    "average_word_list = []\n",
    "for comment in word_list:\n",
    "    average_word_list.append(average_word_length(comment))\n",
    "\n",
    "print(len(average_word_list))    \n",
    "    \n",
    "#Create DataFrame for Summary of Irony STATS\n",
    "summary= pd.DataFrame({\"Average Word Length\": average_word_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment Parsed</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Cola, costs, more, per, litre, than, petrol, ...</td>\n",
       "      <td>[Cola, costs, more, per, litre, than, petrol, ...</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Damn, .,   , I, ca, n't, believe, this, book,...</td>\n",
       "      <td>[Damn,   , I, ca, n't, believe, this, book, se...</td>\n",
       "      <td>[., ., ,, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(My, mother, -, in, -, law, watches, way, to, ...</td>\n",
       "      <td>[My, mother, in, law, watches, way, to, much, ...</td>\n",
       "      <td>[-, -, ,, ,, ,, ., ,, ., ,, \", ,, ,, !, !, \", .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Do, you, know, what, type, of, salt, was, use...</td>\n",
       "      <td>[Do, you, know, what, type, of, salt, was, use...</td>\n",
       "      <td>[?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Also, ,, I, 'm, pretty, sure, surveys, have, ...</td>\n",
       "      <td>[Also, I, 'm, pretty, sure, surveys, have, sho...</td>\n",
       "      <td>[,, ., ,, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Comment Parsed  \\\n",
       "0  (Cola, costs, more, per, litre, than, petrol, ...   \n",
       "1  (Damn, .,   , I, ca, n't, believe, this, book,...   \n",
       "2  (My, mother, -, in, -, law, watches, way, to, ...   \n",
       "3  (Do, you, know, what, type, of, salt, was, use...   \n",
       "4  (Also, ,, I, 'm, pretty, sure, surveys, have, ...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Cola, costs, more, per, litre, than, petrol, ...   \n",
       "1  [Damn,   , I, ca, n't, believe, this, book, se...   \n",
       "2  [My, mother, in, law, watches, way, to, much, ...   \n",
       "3  [Do, you, know, what, type, of, salt, was, use...   \n",
       "4  [Also, I, 'm, pretty, sure, surveys, have, sho...   \n",
       "\n",
       "                                        Punctuation  \n",
       "0                                               [.]  \n",
       "1                                      [., ., ,, .]  \n",
       "2  [-, -, ,, ,, ,, ., ,, ., ,, \", ,, ,, !, !, \", .]  \n",
       "3                                               [?]  \n",
       "4                                      [,, ., ,, .]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create df for total, full returns for irony\n",
    "total_val= pd.DataFrame({'Comment Parsed':tokens})\n",
    "total_val[\"Tokens\"] = word_list\n",
    "total_val[\"Punctuation\"] = punct_list\n",
    "total_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length\n",
       "0             4.555556                10.000000\n",
       "1             4.080000                 9.666667\n",
       "2             3.625000                27.200000\n",
       "3             3.666667                13.000000\n",
       "4             4.704545                24.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SENTENCE LENGTH\n",
    "average_sentence_list = []\n",
    "for x in tokens:\n",
    "    average_sentence_list.append(average_sent_length(x))\n",
    "\n",
    "#Add to Summary of Irony STATS df\n",
    "summary[\"Average Sentence Length\"] = average_sentence_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/S SYMBOLS\n",
    "\n",
    "sarcfunc = []\n",
    "for x in tokens:\n",
    "    sarcfunc.append(check_sarcsymbol(x))\n",
    "\n",
    "\n",
    "sarcsymb_list = []        \n",
    "for l in sarcfunc:\n",
    "    if len(l) >= 1:\n",
    "        sarcsymb_list.append(l)\n",
    "    else:\n",
    "        sarcsymb_list.append([0])\n",
    "\n",
    "#Remove list layer \n",
    "sarcsymb_list = list(chain.from_iterable(sarcsymb_list))\n",
    "\n",
    "\n",
    "\n",
    "summary[\"sarcsymb\"] = sarcsymb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>sarcsymb</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  sarcsymb  \\\n",
       "0             4.555556                10.000000       0.0   \n",
       "1             4.080000                 9.666667       0.0   \n",
       "2             3.625000                27.200000       0.0   \n",
       "3             3.666667                13.000000       0.0   \n",
       "4             4.704545                24.000000       0.0   \n",
       "\n",
       "   Punctuation Richness  \n",
       "0                   6.0  \n",
       "1                  18.5  \n",
       "2                  84.0  \n",
       "3                   7.5  \n",
       "4                  28.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PUNCTUATION RICHNESS\n",
    "average_punct_list = get_punct_average(punct_list, tokens)\n",
    "\n",
    "summary[\"Punctuation Richness\"] = average_punct_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ADJ       ADP       ADV     CCONJ       DET      INTJ      NOUN  \\\n",
       "0  0.100000  0.200000  0.200000       NaN       NaN       NaN  0.200000   \n",
       "1       NaN  0.068966  0.068966  0.034483  0.068966  0.034483  0.172414   \n",
       "2  0.073529  0.088235  0.029412  0.036765  0.088235       NaN  0.161765   \n",
       "3  0.076923  0.153846       NaN       NaN       NaN       NaN  0.307692   \n",
       "4  0.062500  0.125000  0.083333  0.041667  0.020833       NaN  0.187500   \n",
       "\n",
       "        NUM      PART      PRON     PROPN     PUNCT     SPACE       SYM  \\\n",
       "0       NaN       NaN       NaN  0.100000  0.100000       NaN       NaN   \n",
       "1       NaN       NaN  0.103448       NaN  0.137931  0.068966       NaN   \n",
       "2  0.014706  0.022059  0.088235  0.014706  0.117647  0.022059  0.007353   \n",
       "3       NaN       NaN  0.076923       NaN  0.076923       NaN       NaN   \n",
       "4       NaN  0.041667  0.062500       NaN  0.083333  0.020833       NaN   \n",
       "\n",
       "       VERB         X  \n",
       "0  0.100000       NaN  \n",
       "1  0.241379       NaN  \n",
       "2  0.227941  0.007353  \n",
       "3  0.307692       NaN  \n",
       "4  0.270833       NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WORD TYPE AVERAGE \n",
    "\n",
    "average_wordtype_list = []\n",
    "for comment in tokens:\n",
    "    average_wordtype_list.append(relative_count_wordtypes(comment))\n",
    "\n",
    "summary_wordtypedf = pd.DataFrame(average_wordtype_list)\n",
    "summary_wordtypedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>:</th>\n",
       "      <th>:)</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>[</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "      <th>–</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !         \"   #   %   &   '   (   )   *         , ...   :  :)   ;  \\\n",
       "0       NaN       NaN NaN NaN NaN NaN NaN NaN NaN       NaN ... NaN NaN NaN   \n",
       "1       NaN       NaN NaN NaN NaN NaN NaN NaN NaN  0.034483 ... NaN NaN NaN   \n",
       "2  0.014706  0.014706 NaN NaN NaN NaN NaN NaN NaN  0.051471 ... NaN NaN NaN   \n",
       "3       NaN       NaN NaN NaN NaN NaN NaN NaN NaN       NaN ... NaN NaN NaN   \n",
       "4       NaN       NaN NaN NaN NaN NaN NaN NaN NaN  0.041667 ... NaN NaN NaN   \n",
       "\n",
       "          ?   [   ]   _   –   “   ”  \n",
       "0       NaN NaN NaN NaN NaN NaN NaN  \n",
       "1       NaN NaN NaN NaN NaN NaN NaN  \n",
       "2       NaN NaN NaN NaN NaN NaN NaN  \n",
       "3  0.076923 NaN NaN NaN NaN NaN NaN  \n",
       "4       NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INDIVIDUAL PUNCTUATION AVERAGE\n",
    "\n",
    "average_indiv_punc_list = []\n",
    "for x in tokens:\n",
    "    average_indiv_punc_list.append(get_indiv_punct(x))\n",
    "\n",
    "\n",
    "summary_indiv_punct = pd.DataFrame(average_indiv_punc_list)\n",
    "summary_indiv_punct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>sarcsymb</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "      <th>Uppercase Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  sarcsymb  \\\n",
       "0             4.555556                10.000000       0.0   \n",
       "1             4.080000                 9.666667       0.0   \n",
       "2             3.625000                27.200000       0.0   \n",
       "3             3.666667                13.000000       0.0   \n",
       "4             4.704545                24.000000       0.0   \n",
       "\n",
       "   Punctuation Richness  Uppercase Average  \n",
       "0                   6.0           0.000000  \n",
       "1                  18.5           0.034483  \n",
       "2                  84.0           0.051471  \n",
       "3                   7.5           0.000000  \n",
       "4                  28.0           0.020833  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UPPER CASE WORDS (total)\n",
    "\n",
    "uppercase_list = []\n",
    "for b in tokens:\n",
    "    uppercase_list.append((count_uppercase(b)))\n",
    "    \n",
    "#Remove list layer \n",
    "uppercase_list = list(chain.from_iterable(uppercase_list))\n",
    "\n",
    "summary[\"Uppercase Average\"] = uppercase_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>NORP</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDINAL      DATE  EVENT  FAC  GPE  LAW  LOC     MONEY  NORP  ORDINAL  \\\n",
       "0  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "1  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "2  0.007353  0.014706    0.0  0.0  0.0  0.0  0.0  0.007353   0.0      0.0   \n",
       "3  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "4  0.000000  0.000000    0.0  0.0  0.0  0.0  0.0  0.000000   0.0      0.0   \n",
       "\n",
       "        ORG  PERCENT  PERSON  PRODUCT  QUANTITY  TIME  WORK_OF_ART  \n",
       "0  0.000000      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "1  0.000000      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "2  0.007353      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "3  0.000000      0.0     0.0      0.0       0.0   0.0          0.0  \n",
       "4  0.020833      0.0     0.0      0.0       0.0   0.0          0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GET IR ENTITIES \n",
    "named_entity_list = []\n",
    "for comment in tokens:\n",
    "    named_entity_list.append(get_entities(comment))\n",
    "    \n",
    "summary_named_entity = pd.DataFrame(named_entity_list)\n",
    "\n",
    "summary_named_entity = summary_named_entity.replace(np.nan, 0) \n",
    "summary_named_entity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Additional Functions (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_ironic(masterdf, newdf, mastercolumnindex_number, newcolumnindexnumber, weight):\n",
    "    \"\"\"Compares two columns of two dataframes with row index as 0, \n",
    "    based on indices inputted; calculates the difference between the two values and multiples by weight assigned.\n",
    "    Returns list with new feature values\"\"\"\n",
    "    \n",
    "    ironic_average = masterdf.iloc[0][mastercolumnindex_number]\n",
    "      \n",
    "    #access column ONLY and all rows\n",
    "    x = list(newdf.iloc[:,newcolumnindexnumber])\n",
    "\n",
    "    new_list = []\n",
    "    \n",
    "    for item in x:\n",
    "        new_list.append(abs(ironic_average - item)*weight)\n",
    "\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_non_ironic(masterdf, newdf, mastercolumnindex_number, newcolumnindexnumber, weight):\n",
    "    \"\"\"Compares two columns of two dataframes with row index as 1,\n",
    "    based on indices inputted; calculates the difference between the two values \n",
    "    and multiples by the weight assigned.\n",
    "    Returns list with new feature values\"\"\"\n",
    "    \n",
    "    non_ironic_avergae = masterdf.iloc[1][mastercolumnindex_number]\n",
    "      \n",
    "    #access column ONLY and all rows\n",
    "    x = list(newdf.iloc[:,newcolumnindexnumber])\n",
    "\n",
    "    new_list = []\n",
    "    \n",
    "    for item in x:\n",
    "        new_list.append(abs(non_ironic_avergae - item)*weight)\n",
    "\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predicition_results(feature_resultdf):\n",
    "    \"\"\"Take feature dataframe and return list with final classification label\"\"\"\n",
    "    \n",
    "    list_of_tuple_results = [tuple(x) for x in feature_resultdf.to_records(index=False)]\n",
    "    \n",
    "    prediciton_list = []\n",
    "    \n",
    "    for tup in list_of_tuple_results:\n",
    "        non_ironic, ironic = tup\n",
    "    \n",
    "        if non_ironic > ironic:\n",
    "            prediciton_list.append(\"1\") #ironic\n",
    "                \n",
    "        elif non_ironic < ironic:\n",
    "            prediciton_list.append(\"-1\") #non-ironic\n",
    "    \n",
    "    return prediciton_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(testdf):\n",
    "    \"\"\"Compares labelled data with prediction and calculates accuracy of classification\"\"\"\n",
    "    \n",
    "    label = list(testdf.iloc[:,0])\n",
    "    prediciton = list(testdf.iloc[:,2])\n",
    "    list_of_tuple_evaluations = list(zip(label, prediciton))\n",
    "    \n",
    "    gold_match = []\n",
    "    no_match = []\n",
    "    \n",
    "    for tup in list_of_tuple_evaluations:\n",
    "        label, prediction = tup\n",
    "        \n",
    "        if label == int(prediction):\n",
    "            gold_match.append(\"True\") #gold label match\n",
    "                \n",
    "        elif label != int(prediction):\n",
    "            no_match.append(\"False\")\n",
    "            \n",
    "    total_leng = len(testdf)\n",
    "    gold_leng = len(gold_match)\n",
    "    \n",
    "    accuracy = gold_leng / total_leng  \n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Classification\n",
    "\n",
    "Steps:\n",
    "- (1) Import Master DF ###(1) GENERAL\n",
    "- (2) Get Results for each comparison using classification function (1) Ir, (2) Non-ir\n",
    "- (3) Create PredictorDF for (1) Ironic, (2) Non-ironic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''''''''''''''''''''''''''''''\n",
    "- (4) Import Master DF ###(2) POS\n",
    "- (5) Get Results for each comparison using classification function (1) Ir, (2) Non-ir\n",
    "- (6) Add to each PredictorDF for (1) Ironic, (2) Non-ironic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''''''''''''''''''''''''''''''\n",
    "- (7) Import Master DF ###(3) NAMED ENTITY\n",
    "- Repeat steps 5 & 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''''''''''''''''''''''''''''''\n",
    "- (8) Import Master DF ###(4) PUNCTUATION\n",
    "- Repeat steps 5 & 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "####(1)\n",
    "#import GENERAL summary table\n",
    "master_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_general.csv\"\n",
    "mastergeneral_df = pd.read_csv(master_filename)\n",
    "mastergeneral_df.head()\n",
    "\n",
    "mastergeneral_df = mastergeneral_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "ironic_average_word_length = get_classification_ironic(mastergeneral_df, summary, 1, 0, 0.8)\n",
    "ironic_average_sent_length= get_classification_ironic(mastergeneral_df, summary, 2, 1, 1)\n",
    "ironic_average_sarcsymb= get_classification_ironic(mastergeneral_df, summary, 3, 2, 7)\n",
    "ironic_average_uppercase = get_classification_ironic(mastergeneral_df, summary, 4, 4, 1)\n",
    "ironic_punct_richness = get_classification_ironic(mastergeneral_df, summary, 5, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.026120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.004517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.025350\n",
       "1     0.179346         4.595301    4.855297      0.005481   0.009132\n",
       "2     0.543346        12.938032  126.144703      0.005481   0.026120\n",
       "3     0.510013         1.261968   26.855297      0.005481   0.025350\n",
       "4     0.320290         9.738032   14.144703      0.005481   0.004517"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IRONIC\n",
    "#Create PREDICTOR DATAFRAME with classifications (all features)\n",
    "\n",
    "ironic_predictor_df = pd.DataFrame(ironic_average_word_length)\n",
    "ironic_predictor_df.columns = ['WORD LENGTH'] + ironic_predictor_df.columns.tolist()[1:]\n",
    "\n",
    "ironic_predictor_df[\"SENTENCE LENGTH\"] = ironic_average_sent_length\n",
    "ironic_predictor_df[\"PUNCT RICH\"] = ironic_punct_richness\n",
    "ironic_predictor_df[\"SARC SYMB /S\"] = ironic_average_sarcsymb\n",
    "ironic_predictor_df[\"UPPERCASE\"] = ironic_average_uppercase\n",
    "\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON-IRONIC\n",
    "non_ironic_average_word_length = get_classification_non_ironic(mastergeneral_df, summary, 1, 0, 0.8)\n",
    "non_ironic_average_sent_length= get_classification_non_ironic(mastergeneral_df, summary, 2, 1, 1)\n",
    "non_ironic_average_sarcsymb= get_classification_non_ironic(mastergeneral_df, summary, 3, 2, 7)\n",
    "non_ironic_average_uppercase = get_classification_non_ironic(mastergeneral_df, summary, 4, 4, 1)\n",
    "non_ironic_punct_richness = get_classification_non_ironic(mastergeneral_df, summary, 5, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.301945</td>\n",
       "      <td>0.023460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.301945</td>\n",
       "      <td>0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.698055</td>\n",
       "      <td>0.028011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.301945</td>\n",
       "      <td>0.023460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.301945</td>\n",
       "      <td>0.002626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH  UPPERCASE\n",
       "0     0.115636         5.805244           0.0   60.301945   0.023460\n",
       "1     0.264808         6.138577           0.0   35.301945   0.011023\n",
       "2     0.628808        11.394756           0.0   95.698055   0.028011\n",
       "3     0.595475         2.805244           0.0   57.301945   0.023460\n",
       "4     0.234828         8.194756           0.0   16.301945   0.002626"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NON-IRONIC\n",
    "#Create PREDICTOR DATAFRAME with classifications (all features)\n",
    "\n",
    "non_ironic_predictor_df = pd.DataFrame(non_ironic_average_word_length)\n",
    "non_ironic_predictor_df.columns = ['WORD LENGTH'] + non_ironic_predictor_df.columns.tolist()[1:]\n",
    "\n",
    "non_ironic_predictor_df[\"SENTENCE LENGTH\"] = non_ironic_average_sent_length\n",
    "non_ironic_predictor_df[\"SARC SYMB /S\"] = non_ironic_average_sarcsymb\n",
    "non_ironic_predictor_df[\"PUNCT RICH\"] = non_ironic_punct_richness\n",
    "non_ironic_predictor_df[\"UPPERCASE\"] = non_ironic_average_uppercase\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "####(2)\n",
    "#import POS summary table\n",
    "master_wordtype_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_wordtype.csv\"\n",
    "masterwordtype_df = pd.read_csv(master_wordtype_filename)\n",
    "masterwordtype_df.head()\n",
    "\n",
    "masterwordtype_df = masterwordtype_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. PRON, PROPN, NOUN\n",
    "\n",
    "ironic_PRON_dist= get_classification_ironic(masterwordtype_df, summary_wordtypedf, 10, 9, 1)\n",
    "ironic_PROPN_dist_length= get_classification_ironic(masterwordtype_df, summary_wordtypedf, 11, 10, 1)\n",
    "ironic_NOUN_dist = get_classification_ironic(masterwordtype_df, summary_wordtypedf, 7, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.022829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.088269</td>\n",
       "      <td>0.015406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.028632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE  \\\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.025350   \n",
       "1     0.179346         4.595301    4.855297      0.005481   0.009132   \n",
       "2     0.543346        12.938032  126.144703      0.005481   0.026120   \n",
       "3     0.510013         1.261968   26.855297      0.005481   0.025350   \n",
       "4     0.320290         9.738032   14.144703      0.005481   0.004517   \n",
       "\n",
       "       PRON     PROPN      NOUN  \n",
       "0       NaN  0.002975  0.022829  \n",
       "1  0.012317       NaN  0.004757  \n",
       "2  0.002896  0.088269  0.015406  \n",
       "3  0.014209       NaN  0.130521  \n",
       "4  0.028632       NaN  0.010329  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "ironic_predictor_df[\"PRON\"] = ironic_PRON_dist\n",
    "ironic_predictor_df[\"PROPN\"] = ironic_PROPN_dist_length\n",
    "ironic_predictor_df[\"NOUN\"] = ironic_NOUN_dist\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON-IRONIC\n",
    "#E.g. PRON, PROPN, NOUN\n",
    "\n",
    "nonironic_PRON_dist= get_classification_non_ironic(masterwordtype_df, summary_wordtypedf, 10, 9, 1)\n",
    "nonironic_PROPN_dist_length= get_classification_non_ironic(masterwordtype_df, summary_wordtypedf, 11, 10, 1)\n",
    "nonironic_NOUN_dist = get_classification_non_ironic(masterwordtype_df, summary_wordtypedf, 7, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.301945</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.028771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.301945</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.698055</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.009465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.301945</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.301945</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH  UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   60.301945   0.023460   \n",
       "1     0.264808         6.138577           0.0   35.301945   0.011023   \n",
       "2     0.628808        11.394756           0.0   95.698055   0.028011   \n",
       "3     0.595475         2.805244           0.0   57.301945   0.023460   \n",
       "4     0.234828         8.194756           0.0   16.301945   0.002626   \n",
       "\n",
       "       PRON     PROPN      NOUN  \n",
       "0       NaN  0.024394  0.028771  \n",
       "1  0.024472       NaN  0.001184  \n",
       "2  0.009259  0.060900  0.009465  \n",
       "3  0.002053       NaN  0.136463  \n",
       "4  0.016476       NaN  0.016271  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to NON-IRONIC PREDICTOR DATAFRAME\n",
    "non_ironic_predictor_df[\"PRON\"] = nonironic_PRON_dist\n",
    "non_ironic_predictor_df[\"PROPN\"] = nonironic_PROPN_dist_length\n",
    "non_ironic_predictor_df[\"NOUN\"] = nonironic_NOUN_dist\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>NORP</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic</td>\n",
       "      <td>0.041123</td>\n",
       "      <td>0.045283</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.036168</td>\n",
       "      <td>0.044726</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>0.055027</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.03235</td>\n",
       "      <td>0.027053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic</td>\n",
       "      <td>0.034334</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.025125</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>0.017485</td>\n",
       "      <td>0.032427</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.037660</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.021969</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.018885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CARDINAL      DATE     EVENT       FAC       GPE  LANGUAGE  \\\n",
       "0      Ironic  0.041123  0.045283  0.025641  0.003165  0.048072  0.000000   \n",
       "1  Non-ironic  0.034334  0.023964  0.009453  0.012705  0.029929  0.021429   \n",
       "\n",
       "        LAW       LOC     MONEY      NORP   ORDINAL       ORG   PERCENT  \\\n",
       "0  0.015036  0.039665  0.036168  0.044726  0.033967  0.055027  0.045914   \n",
       "1  0.020590  0.019512  0.025125  0.034095  0.017485  0.032427  0.025188   \n",
       "\n",
       "     PERSON   PRODUCT  QUANTITY     TIME  WORK_OF_ART  \n",
       "0  0.047837  0.011140  0.003165  0.03235     0.027053  \n",
       "1  0.037660  0.009576  0.021969  0.01667     0.018885  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####(3)\n",
    "#import NER summary table\n",
    "master_ner_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_namedentity.csv\"\n",
    "masterentity_df = pd.read_csv(master_ner_filename)\n",
    "masterentity_df.head()\n",
    "\n",
    "masterentity_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})\n",
    "masterentity_df = masterentity_df.replace(np.nan, 0)\n",
    "masterentity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. PERSON, LOC, GPE, LANGUAGE (none)\n",
    "\n",
    "ironic_PERSON_dist= get_classification_ironic(masterentity_df, summary_named_entity, 14, 13, 1)\n",
    "ironic_LOC_dist_length= get_classification_ironic(masterentity_df, summary_named_entity, 8, 7, 1)\n",
    "ironic_GPE_dist = get_classification_ironic(masterentity_df, summary_named_entity, 5, 4, 1)\n",
    "ironic_LANGUAGE_dist = get_classification_ironic(masterentity_df, summary_named_entity, 6, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>LOC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.088269</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.028632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE  \\\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.025350   \n",
       "1     0.179346         4.595301    4.855297      0.005481   0.009132   \n",
       "2     0.543346        12.938032  126.144703      0.005481   0.026120   \n",
       "3     0.510013         1.261968   26.855297      0.005481   0.025350   \n",
       "4     0.320290         9.738032   14.144703      0.005481   0.004517   \n",
       "\n",
       "       PRON     PROPN      NOUN    PERSON       LOC       GPE  LANGUAGE  \n",
       "0       NaN  0.002975  0.022829  0.047837  0.039665  0.048072       0.0  \n",
       "1  0.012317       NaN  0.004757  0.047837  0.039665  0.048072       0.0  \n",
       "2  0.002896  0.088269  0.015406  0.047837  0.032312  0.048072       0.0  \n",
       "3  0.014209       NaN  0.130521  0.047837  0.039665  0.048072       0.0  \n",
       "4  0.028632       NaN  0.010329  0.047837  0.039665  0.048072       0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "ironic_predictor_df[\"PERSON\"] = ironic_PERSON_dist\n",
    "ironic_predictor_df[\"LOC\"] = ironic_LOC_dist_length\n",
    "ironic_predictor_df[\"GPE\"] = ironic_GPE_dist\n",
    "ironic_predictor_df[\"LANGUAGE\"] = ironic_LANGUAGE_dist\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. PERSON, LOC, GPE, LANGUAGE (none)\n",
    "\n",
    "nonironic_PERSON_dist= get_classification_non_ironic(masterentity_df, summary_named_entity, 14, 13, 1)\n",
    "nonironic_LOC_dist= get_classification_non_ironic(masterentity_df, summary_named_entity, 8, 7, 1)\n",
    "nonironic_GPE_dist = get_classification_non_ironic(masterentity_df, summary_named_entity, 5, 4, 1)\n",
    "nonironic_LANGUAGE_dist = get_classification_non_ironic(masterentity_df, summary_named_entity, 6, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>LOC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.301945</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.301945</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.698055</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.012159</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.301945</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.301945</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH  UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   60.301945   0.023460   \n",
       "1     0.264808         6.138577           0.0   35.301945   0.011023   \n",
       "2     0.628808        11.394756           0.0   95.698055   0.028011   \n",
       "3     0.595475         2.805244           0.0   57.301945   0.023460   \n",
       "4     0.234828         8.194756           0.0   16.301945   0.002626   \n",
       "\n",
       "       PRON     PROPN      NOUN   PERSON       LOC       GPE  LANGUAGE  \n",
       "0       NaN  0.024394  0.028771  0.03766  0.019512  0.029929  0.021429  \n",
       "1  0.024472       NaN  0.001184  0.03766  0.019512  0.029929  0.021429  \n",
       "2  0.009259  0.060900  0.009465  0.03766  0.012159  0.029929  0.021429  \n",
       "3  0.002053       NaN  0.136463  0.03766  0.019512  0.029929  0.021429  \n",
       "4  0.016476       NaN  0.016271  0.03766  0.019512  0.029929  0.021429  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to NON-IRONIC PREDICTOR DATAFRAME\n",
    "non_ironic_predictor_df[\"PERSON\"] = nonironic_PERSON_dist\n",
    "non_ironic_predictor_df[\"LOC\"] = nonironic_LOC_dist\n",
    "non_ironic_predictor_df[\"GPE\"] = nonironic_GPE_dist\n",
    "non_ironic_predictor_df[\"LANGUAGE\"] = nonironic_LANGUAGE_dist\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>\")</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>---</th>\n",
       "      <th>----------</th>\n",
       "      <th>.</th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>....</th>\n",
       "      <th>.....</th>\n",
       "      <th>......</th>\n",
       "      <th>.......</th>\n",
       "      <th>/</th>\n",
       "      <th>:</th>\n",
       "      <th>:(</th>\n",
       "      <th>:)</th>\n",
       "      <th>:-)</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>[</th>\n",
       "      <th>\\</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "      <th>§</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic</td>\n",
       "      <td>0.093206</td>\n",
       "      <td>0.063918</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047312</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.070586</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.092469</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.048803</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076684</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>0.050782</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050977</td>\n",
       "      <td>0.037716</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023393</td>\n",
       "      <td>0.067477</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.020308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic</td>\n",
       "      <td>0.084272</td>\n",
       "      <td>0.050790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.053885</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.040669</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.070459</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>0.060428</td>\n",
       "      <td>0.092655</td>\n",
       "      <td>0.025933</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.075321</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.021373</td>\n",
       "      <td>0.049411</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122762</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.011914</td>\n",
       "      <td>0.012630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         !         \"        \")         #         %         &  \\\n",
       "0      Ironic  0.093206  0.063918  0.003165  0.000000  0.047312  0.020822   \n",
       "1  Non-ironic  0.084272  0.050790  0.000000  0.027027  0.022251  0.020579   \n",
       "\n",
       "          '         (         )         *         ,         -        --  \\\n",
       "0  0.070586  0.017297  0.018151  0.092469  0.059577  0.048803  0.023541   \n",
       "1  0.053885  0.018097  0.021424  0.055709  0.044991  0.040669  0.018135   \n",
       "\n",
       "        ---  ----------         .        ..       ...      ....     .....  \\\n",
       "0  0.000000    0.000000  0.076684  0.060150  0.050782  0.036945  0.000000   \n",
       "1  0.009804    0.006079  0.070459  0.053516  0.040926  0.060428  0.092655   \n",
       "\n",
       "     ......   .......         /         :        :(        :)       :-)  \\\n",
       "0  0.000000  0.000000  0.050977  0.037716  0.040000  0.062500  0.000000   \n",
       "1  0.025933  0.009434  0.044340  0.014209  0.032215  0.075321  0.012393   \n",
       "\n",
       "          ;         ?         [         \\         ]         _         §  \\\n",
       "0  0.023393  0.067477  0.023683  0.032258  0.032581  0.018987  0.000000   \n",
       "1  0.021373  0.049411  0.076399  0.000000  0.122762  0.011111  0.011765   \n",
       "\n",
       "          –         —         ‘         “         ”  \n",
       "0  0.003165  0.029412  0.003165  0.018484  0.020308  \n",
       "1  0.011765  0.009143  0.008478  0.011914  0.012630  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####(4)\n",
    "#import PUNCTUATION summary table\n",
    "master_punct_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_puncttype.csv\"\n",
    "masterpunct_df = pd.read_csv(master_punct_filename)\n",
    "masterpunct_df.head()\n",
    "\n",
    "masterpunct_df = masterpunct_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})\n",
    "pd.options.display.max_columns = 40\n",
    "masterpunct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for IRONIC\n",
    "#E.g. !, ', *, :( \n",
    "\n",
    "ironic_exclam_dist= get_classification_ironic(masterentity_df, summary_indiv_punct, 1, 0, 1)\n",
    "ironic_apost_dist_length= get_classification_ironic(masterentity_df, summary_indiv_punct, 7, 6, 1)\n",
    "ironic_star_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 10, 9, 1)\n",
    "# ironic_sademoji_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 25, 24, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>LOC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>!</th>\n",
       "      <th>'</th>\n",
       "      <th>*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201098</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>29.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179346</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>4.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543346</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>126.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.088269</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510013</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>26.855297</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>14.144703</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.028632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH  SARC SYMB /S  UPPERCASE  \\\n",
       "0     0.201098         4.261968   29.855297      0.005481   0.025350   \n",
       "1     0.179346         4.595301    4.855297      0.005481   0.009132   \n",
       "2     0.543346        12.938032  126.144703      0.005481   0.026120   \n",
       "3     0.510013         1.261968   26.855297      0.005481   0.025350   \n",
       "4     0.320290         9.738032   14.144703      0.005481   0.004517   \n",
       "\n",
       "       PRON     PROPN      NOUN    PERSON       LOC       GPE  LANGUAGE  \\\n",
       "0       NaN  0.002975  0.022829  0.047837  0.039665  0.048072       0.0   \n",
       "1  0.012317       NaN  0.004757  0.047837  0.039665  0.048072       0.0   \n",
       "2  0.002896  0.088269  0.015406  0.047837  0.032312  0.048072       0.0   \n",
       "3  0.014209       NaN  0.130521  0.047837  0.039665  0.048072       0.0   \n",
       "4  0.028632       NaN  0.010329  0.047837  0.039665  0.048072       0.0   \n",
       "\n",
       "          !   '         *  \n",
       "0       NaN NaN       NaN  \n",
       "1       NaN NaN  0.010243  \n",
       "2  0.026417 NaN  0.006744  \n",
       "3       NaN NaN       NaN  \n",
       "4       NaN NaN  0.003060  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "ironic_predictor_df[\"!\"] = ironic_exclam_dist\n",
    "ironic_predictor_df[\"'\"] = ironic_apost_dist_length\n",
    "ironic_predictor_df[\"*\"] = ironic_star_dist\n",
    "# ironic_predictor_df[\"LANGUAGE\"] = ironic_LANGUAGE_dist\n",
    "ironic_predictor_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification function for NON- IRONIC\n",
    "#E.g. !, ', *, :( \n",
    "\n",
    "nonironic_exclam_dist= get_classification_non_ironic(masterentity_df, summary_indiv_punct, 1, 0, 1)\n",
    "nonironic_apost_dist_length= get_classification_non_ironic(masterentity_df, summary_indiv_punct, 7, 6, 1)\n",
    "nonironic_star_dist = get_classification_non_ironic(masterentity_df, summary_indiv_punct, 10, 9, 1)\n",
    "# ironic_sademoji_dist = get_classification_ironic(masterentity_df, summary_indiv_punct, 25, 24, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>SARC SYMB /S</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>LOC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>!</th>\n",
       "      <th>'</th>\n",
       "      <th>*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115636</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.301945</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264808</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.301945</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628808</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.698055</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.012159</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.019629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595475</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.301945</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234828</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.301945</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  SARC SYMB /S  PUNCT RICH  UPPERCASE  \\\n",
       "0     0.115636         5.805244           0.0   60.301945   0.023460   \n",
       "1     0.264808         6.138577           0.0   35.301945   0.011023   \n",
       "2     0.628808        11.394756           0.0   95.698055   0.028011   \n",
       "3     0.595475         2.805244           0.0   57.301945   0.023460   \n",
       "4     0.234828         8.194756           0.0   16.301945   0.002626   \n",
       "\n",
       "       PRON     PROPN      NOUN   PERSON       LOC       GPE  LANGUAGE  \\\n",
       "0       NaN  0.024394  0.028771  0.03766  0.019512  0.029929  0.021429   \n",
       "1  0.024472       NaN  0.001184  0.03766  0.019512  0.029929  0.021429   \n",
       "2  0.009259  0.060900  0.009465  0.03766  0.012159  0.029929  0.021429   \n",
       "3  0.002053       NaN  0.136463  0.03766  0.019512  0.029929  0.021429   \n",
       "4  0.016476       NaN  0.016271  0.03766  0.019512  0.029929  0.021429   \n",
       "\n",
       "          !   '         *  \n",
       "0       NaN NaN       NaN  \n",
       "1       NaN NaN  0.000388  \n",
       "2  0.019629 NaN  0.017376  \n",
       "3       NaN NaN       NaN  \n",
       "4       NaN NaN  0.007572  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add to IRONIC PREDICTOR DATAFRAME\n",
    "non_ironic_predictor_df[\"!\"] = nonironic_exclam_dist\n",
    "non_ironic_predictor_df[\"'\"] = nonironic_apost_dist_length\n",
    "non_ironic_predictor_df[\"*\"] = nonironic_star_dist\n",
    "# ironic_predictor_df[\"LANGUAGE\"] = ironic_LANGUAGE_dist\n",
    "non_ironic_predictor_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the sum of all features for each comment\n",
    "ironic_feature_prediction = ironic_predictor_df.sum(axis=1)\n",
    "\n",
    "#add final column to ironic predictor df with feature totals\n",
    "ironic_predictor_df[\"Feature Weight\"] = ironic_predictor_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the sum of all features for each comment\n",
    "non_ironic_feature_prediction = non_ironic_predictor_df.sum(axis=1)\n",
    "\n",
    "#add final column to ironic predictor df with feature totals\n",
    "non_ironic_predictor_df[\"Feature Weight\"] = non_ironic_predictor_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-ironic Feature Result</th>\n",
       "      <th>Ironic Feature Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.407978</td>\n",
       "      <td>34.510572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.850927</td>\n",
       "      <td>9.807448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.967435</td>\n",
       "      <td>139.925636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.973168</td>\n",
       "      <td>28.938413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.883003</td>\n",
       "      <td>24.390617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Non-ironic Feature Result  Ironic Feature Result\n",
       "0                  66.407978              34.510572\n",
       "1                  41.850927               9.807448\n",
       "2                 107.967435             139.925636\n",
       "3                  60.973168              28.938413\n",
       "4                  24.883003              24.390617"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create final df with final predicitons\n",
    "final_predictordf = pd.DataFrame(non_ironic_feature_prediction)\n",
    "\n",
    "final_predictordf.columns = [\"Non-ironic Feature Result\"] + final_predictordf.columns.tolist()[1:]\n",
    "final_predictordf[\"Ironic Feature Result\"] = ironic_feature_prediction\n",
    "\n",
    "final_predictordf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "final_prediction = final_predicition_results(final_predictordf)\n",
    "val[\"Prediction\"] = final_prediction\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025641025641026\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy(val)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
