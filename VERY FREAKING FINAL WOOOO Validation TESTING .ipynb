{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import/install all packages at the top\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and read file in df with pandas (for better visualisation)\n",
    "\n",
    "filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/irony-labeled.csv\"\n",
    "\n",
    "gold_label = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns\n",
    "gold_label.columns = [\"Comment_Text\", \"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Train (70), Validation (10) and Test (20) sets\n",
    "\n",
    "-using scikit learn 'train_test_split' function twices gives the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = gold_label[\"Comment_Text\"]\n",
    "x = gold_label[\"Label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=43)\n",
    "\n",
    "#split the training set to get validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas concat joins series together (i.e. dataframes)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "val = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION TESTING WIOOOO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Label                                       Comment_Text\n",
      "1836     -1  Cola costs more per litre than petrol around h...\n",
      "1704     -1  Damn.   I can't believe this book sells.   It'...\n",
      "1656     -1  My mother-in-law watches way to much cable TV,...\n",
      "792      -1  Do you know what type of salt was used for hea...\n",
      "1286     -1  Also, I'm pretty sure surveys have shown that ...\n",
      "1930     -1  I thought this was even more impressive:\\n\\n&g...\n",
      "1639     -1  I think the article made it pretty clear that ...\n",
      "286      -1  Libertarians are the mirror image of communist...\n",
      "692      -1             She's a reformist, not a revolutionary\n",
      "538      -1                    It should have absolutely none.\n",
      "1648      1                        Can't argue with that logic\n",
      "140      -1  She would have much more effect as the chairma...\n",
      "1796     -1  If you think your legislator is too conservati...\n",
      "860      -1  I love this clip sooo much, because she just n...\n",
      "995       1                               who?  the democrats?\n",
      "1766     -1  *challenge*   \\n\\n\\nThis is not a challenge.  ...\n",
      "1316      1                  Yes, expand the pyramid scheme...\n",
      "1183     -1  Do people not understand how currency and buyi...\n",
      "1864     -1  It's ok.  Shit isn't a word you should be conc...\n",
      "1140     -1  Hard to care about that when you're dead. \\n\\n...\n",
      "30       -1  It sounds to me like this is simply a brief ex...\n",
      "380       1  But wait bitcoins arent real nothing was reall...\n",
      "1564     -1                   Hey we have something in common!\n",
      "480      -1  &gt; Membership in this elite group is likely ...\n",
      "1813     -1                        Don't let John Stewart know\n",
      "1154     -1  Spongebob can also support himself while ownin...\n",
      "569       1  The guy who invented basic coverage for everyo...\n",
      "632      -1  ELID: why does Washington want Boeing there if...\n",
      "862      -1                   This is how the grey goo begins.\n",
      "352      -1  &gt; I know you're terrified that your little ...\n",
      "...     ...                                                ...\n",
      "1717     -1                                   Yes. \\n\\n/SAtoSQ\n",
      "1058      1  &gt;They could pass one this very minute if Mr...\n",
      "473      -1  Maybe it's just me, but I'm not really sure wh...\n",
      "278       1  Like they need more incentive not to do their ...\n",
      "1797      1  He's anti-Midas.  Everything he touches turns ...\n",
      "531      -1                              Male sovereign power?\n",
      "579      -1  This would easily go 3000+ upvotes outside of ...\n",
      "1224     -1  FYI - Another identical case just popped up. \\...\n",
      "182      -1  I don't know how any progressive isn't pissed ...\n",
      "721      -1  I wonder what Rob Portman would say about that...\n",
      "1242     -1  If I had a ton of money I'd turn this into a c...\n",
      "605      -1                    What in the howdy fuck is this.\n",
      "1070     -1  The list used to be populated by oil companies...\n",
      "1606     -1  If the republicans would take note that they h...\n",
      "1308     -1  Yes but this tactic isn't protecting the right...\n",
      "1789     -1  And seeing the light on the current drug polic...\n",
      "1599     -1      Took me awhile, but I see what you did there.\n",
      "537      -1                         Nah, am worse in real-ity.\n",
      "297      -1                           +/u/bitcointip $1 verify\n",
      "1539     -1  Here's a deal for Dylan- \\n\\nYou can keep your...\n",
      "1422     -1  Not sure why people are all up in arms about t...\n",
      "392       1  It's funny that you discount this guy's opinio...\n",
      "819       1  It most definitely is.  How could it be constr...\n",
      "994      -1  This is why I love Adam4d's stuff.  Great comi...\n",
      "121      -1  They wouldn't close the plants if an alternati...\n",
      "1786     -1  Consider that 62% of US bankruptcies are due t...\n",
      "1182     -1  I didn't even read the story.  But the headlin...\n",
      "779      -1  At first I thought you meant the shape of the ...\n",
      "570      -1  Part of me thinks Obamacare was designed to fa...\n",
      "160       1  Let's eat popcorn and watch the Teahadists tan...\n",
      "\n",
      "[195 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#check format of train df\n",
    "\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data contains 47 IRONIC comments\n",
      "Training data contains 148 NON- IRONIC comments\n"
     ]
    }
   ],
   "source": [
    "##just so we can get our numbers ie how many of each\n",
    "ironic_val = val[val[\"Label\"] == 1]\n",
    "nonironic_val = val[val[\"Label\"] == -1]\n",
    "\n",
    "print(f\"Training data contains {len(ironic_val)} IRONIC comments\")\n",
    "print(f\"Training data contains {len(nonironic_val)} NON- IRONIC comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "195\n"
     ]
    }
   ],
   "source": [
    "# #Convert into 2 dictionaries\n",
    "val_dict = val.set_index(val.index).T.to_dict()\n",
    "\n",
    "print(len(val_dict))\n",
    "print(len(val_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tokens(test_dict):\n",
    "    \"\"\"Take dictionary and return list of comments as spacy docs\"\"\"\n",
    "    comment_list = []\n",
    "    for comment_index, label in test_dict.items():\n",
    "        for key in label:\n",
    "            text = label[key]\n",
    "            if type(text) == str:\n",
    "                comment_list.append(nlp(text))\n",
    "    return comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(listx):\n",
    "    \"\"\"Take a list (already parsed through SpaCy) remove punctuation and return list of word tokens\"\"\"\n",
    "    ir_clean_docs = [] #remove punctuation\n",
    "\n",
    "    for x in listx:\n",
    "        clean_list = []\n",
    "        for y in x:\n",
    "            if y.pos_ != 'PUNCT':\n",
    "                clean_list.append(y)\n",
    "        ir_clean_docs.append(clean_list)\n",
    "    return ir_clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct(listx):\n",
    "    \"\"\"Take a list (already parsed through spacy), remove words and return list of punctuation ONLY\"\"\"\n",
    "    ir_punct = [] #only punctuation\n",
    "\n",
    "    for x in listx:\n",
    "        clean_list = []\n",
    "        for y in x:\n",
    "            if y.pos_ == 'PUNCT':\n",
    "                clean_list.append(y)\n",
    "        ir_punct.append(clean_list)\n",
    "    return ir_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(doc):\n",
    "    \"\"\"Take doc and return average word length\"\"\"\n",
    "    for token in doc:\n",
    "        word = token.text\n",
    "        average_word_length = sum(len(word) for word in doc) / len(doc)\n",
    "    return(average_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sent_length(doc):\n",
    "    \"\"\"Take doc and return average sentence length\"\"\"\n",
    "    sent_list = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        len_sent = len(sent)\n",
    "        sent_list.append(len_sent)\n",
    "\n",
    "    total = sum(sent_list)\n",
    "    leng = len(sent_list)\n",
    "\n",
    "    average_sent_length = total / leng\n",
    "    return(average_sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_count_wordtypes(doc):\n",
    "    \"\"\"Return relative count average for all word types i.e. nouns, pronouns, verbs etc with word type as key and average as value\"\"\"\n",
    "    pos_tags = []\n",
    "    for token in doc:\n",
    "        pos_tags.append(token.pos_)\n",
    "    counting = Counter(pos_tags) #returns dictionary with whole count for each word type in doc\n",
    "    \n",
    "    leng = len(doc) #overall length of doc (no. of tokens)\n",
    "    new_dict = {}\n",
    "    \n",
    "    for key, value in counting.items(): #iterate over entire dict\n",
    "        new_dict[key] = value/ leng\n",
    "            \n",
    "            \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sarcsymbol(comment_list):\n",
    "    \"\"\"Take a list of comments (parsed through SpaCy); return list of items if \"/s\" is present [Reddit \"/s\" = sarcasm]\"\"\"\n",
    "    sarcsymb = []\n",
    "    for x in comment_list:\n",
    "        for y in x:\n",
    "            if y.text == \"/s\":\n",
    "                sarcsymb.append(x)\n",
    "    return(sarcsymb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct_average(punctuation_list, token_comment_list):\n",
    "    \"\"\"Take preprocessed list of punctuation and full token list (MUST be of equal length); \n",
    "    Returns list of the average for ALL punctuation (based on number overall of tokens)\n",
    "    for each comment\"\"\" \n",
    "\n",
    "    punct_count = []\n",
    "    for comment in punctuation_list:\n",
    "        punct_count.append(len(comment))\n",
    "\n",
    "    len_comment = []\n",
    "    for comment in token_comment_list:\n",
    "        len_comment.append(len(comment))\n",
    "    \n",
    "    punct_count, len_comment = np.array(punct_count), np.array(len_comment) \n",
    "    averages = punct_count + len_comment/2\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indiv_punct(doc):\n",
    "    \"\"\"Return relative count average for all word types i.e. nouns, pronouns, verbs etc with word type as key and average as value\"\"\"\n",
    "    punc_tags = []\n",
    "    for token in doc:\n",
    "        if token.is_punct:\n",
    "            punc_tags.append(token)\n",
    "            \n",
    "    \n",
    "    #make each a string so not multiple keys with same vaues\n",
    "    punc_tags = [str(punc) for punc in punc_tags]\n",
    "           \n",
    "\n",
    "    punc_tag_dict = Counter(punc_tags) #returns dictionary with whole count for each word type in doc\n",
    "    \n",
    "    leng = len(doc) #overall length of doc (no. of tokens)\n",
    "    new_dict = {}\n",
    "    \n",
    "    for key, value in punc_tag_dict.items(): #iterate over entire dict\n",
    "        new_dict[key] = value/ leng\n",
    "            \n",
    "    final_dict = dict(new_dict)\n",
    "            \n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uppercase(doc):\n",
    "    \"\"\"Take nlp doc and return the average number of fully uppercase words for each comment as a list\"\"\"\n",
    "    listd = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_upper == True:\n",
    "            listd.append(token)\n",
    "            \n",
    "    counting = Counter(listd)\n",
    "    \n",
    "    my_dict = dict(counting)\n",
    "    upper_count_avg = []\n",
    "    \n",
    "#     for key, value in my_dict.items():\n",
    "    x = sum(my_dict.values())\n",
    "    upper_count_avg.append(x)\n",
    "#         if key == str:\n",
    "#             my_dict[key] = sum(values)\n",
    "    return upper_count_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(doc):\n",
    "    \"\"\"Take nlp doc and return a dictionary with key as ent.labe_ and value as the average number\"\"\"\n",
    "    entity = []\n",
    "    for token in doc.ents:\n",
    "        entity.append(token.label_)\n",
    "\n",
    "    new_dict = Counter(entity)\n",
    "    leng = len(doc)\n",
    "    \n",
    "    for key, value in new_dict.items():\n",
    "        new_dict[key] = value / leng\n",
    "        \n",
    "    ent_dict = dict(new_dict)\n",
    "    \n",
    "    return ent_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START THE VAL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) GET ALL TOKENS\n",
    "tokens = get_all_tokens(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Get list of ONLY words (no punct)\n",
    "word_list = get_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Get list of ONLY punct (no words)\n",
    "punct_list = get_punct(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment Parsed</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Cola, costs, more, per, litre, than, petrol, ...</td>\n",
       "      <td>[Cola, costs, more, per, litre, than, petrol, ...</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Damn, .,   , I, ca, n't, believe, this, book,...</td>\n",
       "      <td>[Damn,   , I, ca, n't, believe, this, book, se...</td>\n",
       "      <td>[., ., ,, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(My, mother, -, in, -, law, watches, way, to, ...</td>\n",
       "      <td>[My, mother, in, law, watches, way, to, much, ...</td>\n",
       "      <td>[-, -, ,, ,, ,, ., ,, ., ,, \", ,, ,, !, !, \", .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Do, you, know, what, type, of, salt, was, use...</td>\n",
       "      <td>[Do, you, know, what, type, of, salt, was, use...</td>\n",
       "      <td>[?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Also, ,, I, 'm, pretty, sure, surveys, have, ...</td>\n",
       "      <td>[Also, I, 'm, pretty, sure, surveys, have, sho...</td>\n",
       "      <td>[,, ., ,, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Comment Parsed  \\\n",
       "0  (Cola, costs, more, per, litre, than, petrol, ...   \n",
       "1  (Damn, .,   , I, ca, n't, believe, this, book,...   \n",
       "2  (My, mother, -, in, -, law, watches, way, to, ...   \n",
       "3  (Do, you, know, what, type, of, salt, was, use...   \n",
       "4  (Also, ,, I, 'm, pretty, sure, surveys, have, ...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Cola, costs, more, per, litre, than, petrol, ...   \n",
       "1  [Damn,   , I, ca, n't, believe, this, book, se...   \n",
       "2  [My, mother, in, law, watches, way, to, much, ...   \n",
       "3  [Do, you, know, what, type, of, salt, was, use...   \n",
       "4  [Also, I, 'm, pretty, sure, surveys, have, sho...   \n",
       "\n",
       "                                        Punctuation  \n",
       "0                                               [.]  \n",
       "1                                      [., ., ,, .]  \n",
       "2  [-, -, ,, ,, ,, ., ,, ., ,, \", ,, ,, !, !, \", .]  \n",
       "3                                               [?]  \n",
       "4                                      [,, ., ,, .]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create df for total, full returns for irony\n",
    "total_val= pd.DataFrame({'Comment Parsed':tokens})\n",
    "total_val[\"Tokens\"] = word_list\n",
    "total_val[\"Punctuation\"] = punct_list\n",
    "total_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) WORD LENGTH\n",
    "average_word_list = []\n",
    "for comment in word_list:\n",
    "    average_word_list.append(average_word_length(comment))\n",
    "\n",
    "#Create DataFrame for Summary of Irony STATS\n",
    "summary= pd.DataFrame({\"Average Word Length\": average_word_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length\n",
       "0             4.555556                10.000000\n",
       "1             4.080000                 9.666667\n",
       "2             3.625000                27.200000\n",
       "3             3.666667                13.000000\n",
       "4             4.704545                24.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SENTENCE LENGTH\n",
    "average_sentence_list = []\n",
    "for x in tokens:\n",
    "    average_sentence_list.append(average_sent_length(x))\n",
    "\n",
    "#Add to Summary of Irony STATS df\n",
    "summary[\"Average Sentence Length\"] = average_sentence_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/S SYMBOLS\n",
    "\n",
    "sarcsymb = check_sarcsymbol(tokens)\n",
    "sarcsymb = (len(sarcsymb))\n",
    "\n",
    "summary[\"sarcsymb\"] = sarcsymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>sarcsymb</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  sarcsymb  \\\n",
       "0             4.555556                10.000000         2   \n",
       "1             4.080000                 9.666667         2   \n",
       "2             3.625000                27.200000         2   \n",
       "3             3.666667                13.000000         2   \n",
       "4             4.704545                24.000000         2   \n",
       "\n",
       "   Punctuation Richness  \n",
       "0                   6.0  \n",
       "1                  18.5  \n",
       "2                  84.0  \n",
       "3                   7.5  \n",
       "4                  28.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PUNCTUATION RICHNESS\n",
    "average_punct_list = get_punct_average(punct_list, tokens)\n",
    "\n",
    "summary[\"Punctuation Richness\"] = average_punct_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ADJ       ADP       ADV     CCONJ       DET      INTJ      NOUN  \\\n",
       "0  0.100000  0.200000  0.200000       NaN       NaN       NaN  0.200000   \n",
       "1       NaN  0.068966  0.068966  0.034483  0.068966  0.034483  0.172414   \n",
       "2  0.073529  0.088235  0.029412  0.036765  0.088235       NaN  0.161765   \n",
       "3  0.076923  0.153846       NaN       NaN       NaN       NaN  0.307692   \n",
       "4  0.062500  0.125000  0.083333  0.041667  0.020833       NaN  0.187500   \n",
       "\n",
       "        NUM      PART      PRON     PROPN     PUNCT     SPACE       SYM  \\\n",
       "0       NaN       NaN       NaN  0.100000  0.100000       NaN       NaN   \n",
       "1       NaN       NaN  0.103448       NaN  0.137931  0.068966       NaN   \n",
       "2  0.014706  0.022059  0.088235  0.014706  0.117647  0.022059  0.007353   \n",
       "3       NaN       NaN  0.076923       NaN  0.076923       NaN       NaN   \n",
       "4       NaN  0.041667  0.062500       NaN  0.083333  0.020833       NaN   \n",
       "\n",
       "       VERB         X  \n",
       "0  0.100000       NaN  \n",
       "1  0.241379       NaN  \n",
       "2  0.227941  0.007353  \n",
       "3  0.307692       NaN  \n",
       "4  0.270833       NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WORD TYPE AVERAGE \n",
    "\n",
    "average_wordtype_list = []\n",
    "for comment in tokens:\n",
    "    average_wordtype_list.append(relative_count_wordtypes(comment))\n",
    "\n",
    "summary_wordtypedf = pd.DataFrame(average_wordtype_list)\n",
    "summary_wordtypedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>:</th>\n",
       "      <th>:)</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>[</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "      <th>–</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !         \"   #   %   &   '   (   )   *         , ...   :  :)   ;  \\\n",
       "0       NaN       NaN NaN NaN NaN NaN NaN NaN NaN       NaN ... NaN NaN NaN   \n",
       "1       NaN       NaN NaN NaN NaN NaN NaN NaN NaN  0.034483 ... NaN NaN NaN   \n",
       "2  0.014706  0.014706 NaN NaN NaN NaN NaN NaN NaN  0.051471 ... NaN NaN NaN   \n",
       "3       NaN       NaN NaN NaN NaN NaN NaN NaN NaN       NaN ... NaN NaN NaN   \n",
       "4       NaN       NaN NaN NaN NaN NaN NaN NaN NaN  0.041667 ... NaN NaN NaN   \n",
       "\n",
       "          ?   [   ]   _   –   “   ”  \n",
       "0       NaN NaN NaN NaN NaN NaN NaN  \n",
       "1       NaN NaN NaN NaN NaN NaN NaN  \n",
       "2       NaN NaN NaN NaN NaN NaN NaN  \n",
       "3  0.076923 NaN NaN NaN NaN NaN NaN  \n",
       "4       NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INDIVIDUAL PUNCTUATION AVERAGE\n",
    "\n",
    "average_indiv_punc_list = []\n",
    "for x in tokens:\n",
    "    average_indiv_punc_list.append(get_indiv_punct(x))\n",
    "\n",
    "summary_indiv_punct = pd.DataFrame(average_indiv_punc_list)\n",
    "summary_indiv_punct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>sarcsymb</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "      <th>Uppercase Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.704545</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Word Length  Average Sentence Length  sarcsymb  \\\n",
       "0             4.555556                10.000000         2   \n",
       "1             4.080000                 9.666667         2   \n",
       "2             3.625000                27.200000         2   \n",
       "3             3.666667                13.000000         2   \n",
       "4             4.704545                24.000000         2   \n",
       "\n",
       "   Punctuation Richness Uppercase Average  \n",
       "0                   6.0               [0]  \n",
       "1                  18.5               [1]  \n",
       "2                  84.0               [7]  \n",
       "3                   7.5               [0]  \n",
       "4                  28.0               [1]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UPPER CASE WORDS (total)\n",
    "\n",
    "uppercase_list = []\n",
    "for b in tokens:\n",
    "    uppercase_list.append((count_uppercase(b)))\n",
    "\n",
    "summary[\"Uppercase Average\"] = uppercase_list\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET IR ENTITIES \n",
    "named_entity_list = []\n",
    "for comment in tokens:\n",
    "    named_entity_list.append(get_entities(comment))\n",
    "    \n",
    "summary_named_entity = pd.DataFrame(named_entity_list)\n",
    "\n",
    "# summary_named_entity.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import master general table for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Number of '/s' symbols</th>\n",
       "      <th>Punctuation Richness</th>\n",
       "      <th>Average Number of Uppercase Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironic Comments</td>\n",
       "      <td>4.304183</td>\n",
       "      <td>14.261968</td>\n",
       "      <td>3</td>\n",
       "      <td>18.701550</td>\n",
       "      <td>0.749354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-ironic Comments</td>\n",
       "      <td>4.411010</td>\n",
       "      <td>15.805244</td>\n",
       "      <td>0</td>\n",
       "      <td>32.517912</td>\n",
       "      <td>1.132037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Class  Average Word Length  Average Sentence Length  \\\n",
       "0      Ironic Comments             4.304183                14.261968   \n",
       "1  Non-ironic Comments             4.411010                15.805244   \n",
       "\n",
       "   Number of '/s' symbols  Punctuation Richness  \\\n",
       "0                       3             18.701550   \n",
       "1                       0             32.517912   \n",
       "\n",
       "   Average Number of Uppercase Words  \n",
       "0                           0.749354  \n",
       "1                           1.132037  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_general.csv\"\n",
    "mastergeneral_df = pd.read_csv(master_filename)\n",
    "mastergeneral_df.head()\n",
    "\n",
    "mastergeneral_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference between average word master and new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "#mastergeneral_df\n",
    "\n",
    "def get_classification_ironic(masterdf, newdf, mastercolumnindex_number, newcolumnindexnumber, weight):\n",
    "    \n",
    "    ironic_word_avergae = masterdf.iloc[0][mastercolumnindex_number]\n",
    "      \n",
    "    #access column ONLY and all rows\n",
    "    x = list(newdf.iloc[:,newcolumnindexnumber])\n",
    "\n",
    "    new_list = []\n",
    "    \n",
    "    for item in x:\n",
    "        new_list.append(abs(ironic_word_avergae - item)*weight)\n",
    "\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get results from classification determiner\n",
    "ironic_average_word_length = get_classification_ironic(mastergeneral_df, summary, 1, 0, 1)\n",
    "ironic_average_sent_length= get_classification_ironic(mastergeneral_df, summary, 2, 1, 1)\n",
    "ironic_punct_richness = get_classification_ironic(mastergeneral_df, summary, 4, 3, 1)\n",
    "ironic_average_uppercase = get_classification_ironic(mastergeneral_df, summary, 5, 4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251373</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>12.70155</td>\n",
       "      <td>[0.7493540051679587]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224183</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>0.20155</td>\n",
       "      <td>[0.2506459948320413]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679183</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>65.29845</td>\n",
       "      <td>[6.250645994832041]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637516</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>11.20155</td>\n",
       "      <td>[0.7493540051679587]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400363</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>9.29845</td>\n",
       "      <td>[0.2506459948320413]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH             UPPERCASE\n",
       "0     0.251373         4.261968    12.70155  [0.7493540051679587]\n",
       "1     0.224183         4.595301     0.20155  [0.2506459948320413]\n",
       "2     0.679183        12.938032    65.29845   [6.250645994832041]\n",
       "3     0.637516         1.261968    11.20155  [0.7493540051679587]\n",
       "4     0.400363         9.738032     9.29845  [0.2506459948320413]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create PREDICTOR DATAFRAME with classifications\n",
    "\n",
    "ironic_predictor_df = pd.DataFrame(ironic_average_word_length)\n",
    "\n",
    "ironic_predictor_df.columns = ['WORD LENGTH'] + ironic_predictor_df.columns.tolist()[1:]\n",
    "\n",
    "ironic_predictor_df[\"SENTENCE LENGTH\"] = ironic_average_sent_length\n",
    "ironic_predictor_df[\"PUNCT RICH\"] = ironic_punct_richness\n",
    "ironic_predictor_df[\"UPPERCASE\"] = ironic_average_uppercase\n",
    "\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ironic_feature_prediction = ironic_predictor_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>Feature Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251373</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>12.70155</td>\n",
       "      <td>[0.7493540051679587]</td>\n",
       "      <td>17.964245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224183</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>0.20155</td>\n",
       "      <td>[0.2506459948320413]</td>\n",
       "      <td>5.271680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679183</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>65.29845</td>\n",
       "      <td>[6.250645994832041]</td>\n",
       "      <td>85.166310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637516</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>11.20155</td>\n",
       "      <td>[0.7493540051679587]</td>\n",
       "      <td>13.850388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400363</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>9.29845</td>\n",
       "      <td>[0.2506459948320413]</td>\n",
       "      <td>19.687491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH             UPPERCASE  \\\n",
       "0     0.251373         4.261968    12.70155  [0.7493540051679587]   \n",
       "1     0.224183         4.595301     0.20155  [0.2506459948320413]   \n",
       "2     0.679183        12.938032    65.29845   [6.250645994832041]   \n",
       "3     0.637516         1.261968    11.20155  [0.7493540051679587]   \n",
       "4     0.400363         9.738032     9.29845  [0.2506459948320413]   \n",
       "\n",
       "   Feature Weight  \n",
       "0       17.964245  \n",
       "1        5.271680  \n",
       "2       85.166310  \n",
       "3       13.850388  \n",
       "4       19.687491  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ironic_predictor_df[\"Feature Weight\"] = ironic_predictor_df.sum(axis=1)\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_non_ironic(masterdf, newdf, mastercolumnindex_number, newcolumnindexnumber, weight):\n",
    "    \n",
    "    non_ironic_word_avergae = masterdf.iloc[1][mastercolumnindex_number]\n",
    "      \n",
    "    #access column ONLY and all rows\n",
    "    x = list(newdf.iloc[:,newcolumnindexnumber])\n",
    "\n",
    "    new_list = []\n",
    "    \n",
    "    for item in x:\n",
    "        new_list.append(abs(non_ironic_word_avergae - item)*weight)\n",
    "\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "      <th>Feature Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251373</td>\n",
       "      <td>4.261968</td>\n",
       "      <td>12.70155</td>\n",
       "      <td>[0.7493540051679587]</td>\n",
       "      <td>17.964245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224183</td>\n",
       "      <td>4.595301</td>\n",
       "      <td>0.20155</td>\n",
       "      <td>[0.2506459948320413]</td>\n",
       "      <td>5.271680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679183</td>\n",
       "      <td>12.938032</td>\n",
       "      <td>65.29845</td>\n",
       "      <td>[6.250645994832041]</td>\n",
       "      <td>85.166310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637516</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>11.20155</td>\n",
       "      <td>[0.7493540051679587]</td>\n",
       "      <td>13.850388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400363</td>\n",
       "      <td>9.738032</td>\n",
       "      <td>9.29845</td>\n",
       "      <td>[0.2506459948320413]</td>\n",
       "      <td>19.687491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH             UPPERCASE  \\\n",
       "0     0.251373         4.261968    12.70155  [0.7493540051679587]   \n",
       "1     0.224183         4.595301     0.20155  [0.2506459948320413]   \n",
       "2     0.679183        12.938032    65.29845   [6.250645994832041]   \n",
       "3     0.637516         1.261968    11.20155  [0.7493540051679587]   \n",
       "4     0.400363         9.738032     9.29845  [0.2506459948320413]   \n",
       "\n",
       "   Feature Weight  \n",
       "0       17.964245  \n",
       "1        5.271680  \n",
       "2       85.166310  \n",
       "3       13.850388  \n",
       "4       19.687491  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get results from classification determiner\n",
    "non_ironic_average_word_length = get_classification_non_ironic(mastergeneral_df, summary, 1, 0, 1)\n",
    "non_ironic_average_sent_length= get_classification_non_ironic(mastergeneral_df, summary, 2, 1, 1)\n",
    "non_ironic_punct_richness = get_classification_non_ironic(mastergeneral_df, summary, 4, 3, 1)\n",
    "non_ironic_average_uppercase = get_classification_non_ironic(mastergeneral_df, summary, 5, 4, 1)\n",
    "\n",
    "ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD LENGTH</th>\n",
       "      <th>SENTENCE LENGTH</th>\n",
       "      <th>PUNCT RICH</th>\n",
       "      <th>UPPERCASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.144545</td>\n",
       "      <td>5.805244</td>\n",
       "      <td>26.517912</td>\n",
       "      <td>[1.1320368474923237]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.331010</td>\n",
       "      <td>6.138577</td>\n",
       "      <td>14.017912</td>\n",
       "      <td>[0.1320368474923237]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.786010</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>51.482088</td>\n",
       "      <td>[5.867963152507676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.744344</td>\n",
       "      <td>2.805244</td>\n",
       "      <td>25.017912</td>\n",
       "      <td>[1.1320368474923237]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.293535</td>\n",
       "      <td>8.194756</td>\n",
       "      <td>4.517912</td>\n",
       "      <td>[0.1320368474923237]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORD LENGTH  SENTENCE LENGTH  PUNCT RICH             UPPERCASE\n",
       "0     0.144545         5.805244   26.517912  [1.1320368474923237]\n",
       "1     0.331010         6.138577   14.017912  [0.1320368474923237]\n",
       "2     0.786010        11.394756   51.482088   [5.867963152507676]\n",
       "3     0.744344         2.805244   25.017912  [1.1320368474923237]\n",
       "4     0.293535         8.194756    4.517912  [0.1320368474923237]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create PREDICTOR DATAFRAME with classifications\n",
    "\n",
    "non_ironic_predictor_df = pd.DataFrame(non_ironic_average_word_length)\n",
    "\n",
    "non_ironic_predictor_df.columns = ['WORD LENGTH'] + non_ironic_predictor_df.columns.tolist()[1:]\n",
    "\n",
    "non_ironic_predictor_df[\"SENTENCE LENGTH\"] = non_ironic_average_sent_length\n",
    "non_ironic_predictor_df[\"PUNCT RICH\"] = non_ironic_punct_richness\n",
    "non_ironic_predictor_df[\"UPPERCASE\"] = non_ironic_average_uppercase\n",
    "non_ironic_predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ironic_feature_prediction = non_ironic_predictor_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ironic_predictor_df[\"Feature Weight\"] = non_ironic_predictor_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-ironic Feature Result</th>\n",
       "      <th>Ironic Feature Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.599738</td>\n",
       "      <td>17.964245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.619536</td>\n",
       "      <td>5.271680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.530817</td>\n",
       "      <td>85.166310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.699536</td>\n",
       "      <td>13.850388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.138240</td>\n",
       "      <td>19.687491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Non-ironic Feature Result  Ironic Feature Result\n",
       "0                  33.599738              17.964245\n",
       "1                  20.619536               5.271680\n",
       "2                  69.530817              85.166310\n",
       "3                  29.699536              13.850388\n",
       "4                  13.138240              19.687491"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create final df with final predicitons\n",
    "final_predictordf = pd.DataFrame(non_ironic_feature_prediction)\n",
    "\n",
    "final_predictordf.columns = [\"Non-ironic Feature Result\"] + final_predictordf.columns.tolist()[1:]\n",
    "final_predictordf[\"Ironic Feature Result\"] = ironic_feature_prediction\n",
    "\n",
    "final_predictordf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return list of ïronic vs non-ironic strings from column with lowest number\n",
    "\n",
    "\n",
    "def final_predicition_results(feature_resultdf):\n",
    "    \n",
    "    list_of_tuple_results = [tuple(x) for x in feature_resultdf.to_records(index=False)]\n",
    "    \n",
    "    prediciton_list = []\n",
    "    \n",
    "    for tup in list_of_tuple_results:\n",
    "        non_ironic, ironic = tup\n",
    "    \n",
    "        if non_ironic > ironic:\n",
    "            prediciton_list.append(\"1\") #ironic\n",
    "                \n",
    "        elif non_ironic < ironic:\n",
    "            prediciton_list.append(\"-1\") #non-ironic\n",
    "    \n",
    "    \n",
    "    \n",
    "    return prediciton_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "final_prediction = final_predicition_results(final_predictordf)\n",
    "val[\"Prediction\"] = final_prediction\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(testdf):\n",
    "    \n",
    "    label = list(testdf.iloc[:,0])\n",
    "    prediciton = list(testdf.iloc[:,2])\n",
    "    list_of_tuple_evaluations = list(zip(label, prediciton))\n",
    "    \n",
    "    gold_match = []\n",
    "    no_match = []\n",
    "    \n",
    "    for tup in list_of_tuple_evaluations:\n",
    "        label, prediction = tup\n",
    "        \n",
    "        if label == int(prediction):\n",
    "            gold_match.append(\"True\") #gold label match\n",
    "                \n",
    "        elif label != int(prediction):\n",
    "            no_match.append(\"False\")\n",
    "            \n",
    "    total_leng = len(testdf)\n",
    "    \n",
    "    gold_leng = len(gold_match)\n",
    "    \n",
    "    accuracy = gold_leng / total_leng  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517948717948718\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy(val)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import wordtype count master for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_wordtype_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_wordtype.csv\"\n",
    "masterwordtype_df = pd.read_csv(master_filename)\n",
    "masterwordtype_df.head()\n",
    "\n",
    "masterwordtype_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import NER count master for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_ner_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_namedentity.csv\"\n",
    "masterentity_df = pd.read_csv(master_ner_filename)\n",
    "masterentity_df.head()\n",
    "\n",
    "masterentity_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import punctuation type count master for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_punct_filename= \"/Users/laure/OneDrive/Dokumente/VU/Python for Text Analysis/Final Assignment/train_summary_puncttype.csv\"\n",
    "masterpunct_df = pd.read_csv(master_punct_filename)\n",
    "masterpunct_df.head()\n",
    "\n",
    "masterpunct_df.rename(columns={mastergeneral_df.columns[0]: \"Class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
